{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\" #imports\n",
    "#imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "%config Completer.use_jedi = False\n",
    "from torch_scatter import scatter\n",
    "\n",
    "%env CUDA_LAUNCH_BLOCKING 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8054/495279268.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aspect/anaconda3/envs/extensions/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch_geometric\n",
    "import pysat as ps\n",
    "# import gurobipy as gp\n",
    "# from gurobipy import GRB\n",
    "\n",
    "from pysat.formula import CNF\n",
    "from matplotlib import pyplot as plt\n",
    "from pysat.solvers import Lingeling\n",
    "\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "from IPython.core.debugger import set_trace\n",
    "from datetime import date\n",
    "#from kernel.datasets import get_dataset\n",
    "from itertools import product\n",
    "import time\n",
    "from torch import tensor\n",
    "from torch.optim import Adam\n",
    "from torch.optim import SGD\n",
    "from torch.nn import PReLU\n",
    "from torch_geometric.data import DataLoader, DenseDataLoader as DenseLoader\n",
    "from math import ceil\n",
    "from torch.nn import Linear\n",
    "from torch.distributions import categorical\n",
    "from torch.distributions import Bernoulli\n",
    "import torch.nn\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from torch_geometric.utils import convert as cnv\n",
    "from torch_geometric.utils import sparse as sp\n",
    "from torch_geometric.data import Data\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "import networkx as nx\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "from torch.nn.functional import gumbel_softmax\n",
    "from torch.distributions import relaxed_categorical\n",
    "from torch_geometric.nn.inits import uniform\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import degree\n",
    "from torch_geometric.nn import GINConv, GATConv, global_mean_pool, NNConv, GCNConv\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU, LeakyReLU\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Sequential, ReLU, BatchNorm1d as BN\n",
    "from torch_geometric.nn import GINConv, global_mean_pool\n",
    "from torch_geometric.data import Batch \n",
    "from torch import autograd\n",
    "from torch_geometric.utils import to_dense_batch, to_dense_adj\n",
    "from torch_geometric.utils import softmax, add_self_loops, remove_self_loops, segregate_self_loops, remove_isolated_nodes, contains_isolated_nodes, add_remaining_self_loops\n",
    "from torch_geometric.utils import dropout_adj, to_undirected, to_networkx\n",
    "from torch_geometric.utils import is_undirected\n",
    "import scipy\n",
    "import scipy.io\n",
    "from matplotlib.lines import Line2D\n",
    "from torch_geometric.utils.convert import from_scipy_sparse_matrix\n",
    "from networkx.algorithms.approximation import max_clique\n",
    "import pickle\n",
    "from torch_geometric.nn import SplineConv, global_mean_pool, DataParallel\n",
    "from torch_geometric.data import DataListLoader\n",
    "from random import shuffle\n",
    "from networkx.algorithms.approximation import max_clique\n",
    "from networkx.algorithms import find_cliques\n",
    "from torch_geometric.nn.norm import graph_size_norm\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from torch_geometric.nn import GatedGraphConv, GINEConv\n",
    "import os\n",
    "from pysat.solvers import Lingeling,Minisat22, Glucose4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_dense_to_sparse(tensor):\n",
    "    r\"\"\"Converts a dense adjacency matrix to a sparse adjacency matrix defined\n",
    "    by edge indices and edge attributes.\n",
    "\n",
    "    Args:\n",
    "        tensor (Tensor): The dense adjacency matrix.\n",
    "     :rtype: (:class:`LongTensor`, :class:`Tensor`)\n",
    "    \"\"\"\n",
    "    assert tensor.dim() == 2\n",
    "    index = tensor.nonzero(as_tuple=False).t().contiguous()\n",
    "    value = tensor[index[0], index[1]]\n",
    "    return index, value            \n",
    "                        \n",
    "def generate_random_kCNF(k,num_variables, num_clauses):\n",
    "    formula = CNF()\n",
    "    for clause_i in range(num_clauses):\n",
    "        clause = []\n",
    "        for literal in range(k):\n",
    "            #randint is not inclusive on the upper bound, hence +1\n",
    "            literal = np.random.randint(-num_variables,num_variables+1)\n",
    "            while (literal in clause) or (-literal in clause) or (literal==0):\n",
    "                    literal = np.random.randint(-num_variables,num_variables+1)\n",
    "            clause += [literal]\n",
    "        formula.append(clause)\n",
    "    return formula\n",
    "\n",
    "#detect dependencies between clauses (2 clauses have a dependency if they share a variable)\n",
    "#dependencies are lopsided, a variable and its negative will connect two clauses with a negative sign\n",
    "def detect_dependency_2(clause_1, clause_2):\n",
    "    dependency_score = 0\n",
    "    for  var_1 in clause_1:\n",
    "        for var_2 in clause_2:\n",
    "            if np.abs(var_1) == np.abs(var_2):\n",
    "                if np.sign(var_1)==np.sign(var_2):\n",
    "                    return 1\n",
    "                else:\n",
    "                    return -1\n",
    "            \n",
    "    return 0\n",
    "\n",
    "\n",
    "def detect_dependency(clause_1, clause_2):\n",
    "    dependency_score = 0\n",
    "    for  var_1 in clause_1:\n",
    "        for var_2 in clause_2:\n",
    "            if np.abs(var_1) == np.abs(var_2):\n",
    "                if np.sign(var_1)==np.sign(var_2):\n",
    "                    dependency_score = 1\n",
    "                else:\n",
    "                    return -1\n",
    "            \n",
    "    return dependency_score\n",
    "\n",
    "def get_VarClause_matrix(formula,k):\n",
    "    clause_var_adj = np.zeros((len(formula.clauses)+formula.nv,len(formula.clauses)+formula.nv))\n",
    "    clause_var_dir = np.zeros((formula.nv,formula.nv+len(formula.clauses)))\n",
    "    for i in range(len(formula.clauses)):\n",
    "        for j in range(k):\n",
    "            literal = formula.clauses[i][j] \n",
    "            clause_var_adj[i,np.abs(literal)-1] =  np.sign(literal)\n",
    "            clause_var_dir[np.abs(literal)-1,i+formula.nv] = np.sign(literal)\n",
    "    return clause_var_adj, clause_var_dir\n",
    "    \n",
    "def get_VarClause_matrix_2(formula,k):\n",
    "    clause_var_adj = np.zeros((len(formula.clauses)+formula.nv,len(formula.clauses)+formula.nv))\n",
    "    clause_var_dir = np.zeros((formula.nv,formula.nv+len(formula.clauses)))\n",
    "    for i in range(len(formula.clauses)):\n",
    "        for j in range(k):\n",
    "            literal = formula.clauses[i][j] \n",
    "            clause_var_adj[i,np.abs(literal)-1] =  np.sign(literal)\n",
    "            clause_var_dir[np.abs(literal)-1,i+formula.nv] = np.sign(literal)\n",
    "    return clause_var_adj, clause_var_dir\n",
    "    \n",
    "    \n",
    "  \n",
    "def get_dependency_matrix(formula):\n",
    "    num_clauses = len(formula.clauses)\n",
    "    dependency_graph_adj = np.zeros((len(formula.clauses)+formula.nv,len(formula.clauses)+formula.nv))\n",
    "    for row in range(num_clauses):\n",
    "        for column in range(num_clauses):\n",
    "            dependency_graph_adj[row+formula.nv,column+formula.nv] = detect_dependency(formula.clauses[row], formula.clauses[column])\n",
    "    return dependency_graph_adj- np.eye(dependency_graph_adj.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "def generate_dimacs_CNFDataset(dimacs_dataset, k):\n",
    "    dataset=[]\n",
    "    \n",
    "    for (counter,formula) in enumerate(dimacs_dataset):\n",
    "\n",
    "        with Glucose4(bootstrap_with=formula.clauses, with_proof=True) as l:\n",
    "            is_sat = (l.solve())\n",
    "            \n",
    "        num_variables = len(set([np.abs(item) for sublist in (formula.clauses) for item in sublist]))\n",
    "        num_clauses  = len(formula.clauses)\n",
    "\n",
    "        #adj_matrix = get_dependency_matrix(formula)\n",
    "        var_clause_mat, var_clause_dirmat = get_VarClause_matrix(formula,k)\n",
    "        \n",
    "        #delete isolated node rows,columns from clause-clause graph and var-clause graph\n",
    "        #adj_matrix = np.delete(adj_matrix,np.where((np.abs(var_clause_dirmat).sum(1)[:formula.nv]==0))[0],axis=0)\n",
    "        #adj_matrix = np.delete(adj_matrix,np.where((np.abs(var_clause_dirmat).sum(1)[:formula.nv]==0))[0],axis=1)\n",
    "\n",
    "\n",
    "        var_clause_dirmat_temp = np.delete(var_clause_dirmat,np.where((np.abs(var_clause_dirmat).sum(1)[:formula.nv]==0))[0],axis=0)\n",
    "        var_clause_dirmat_temp = np.delete(var_clause_dirmat_temp,np.where((np.abs(var_clause_dirmat).sum(1)[:formula.nv]==0))[0],axis=1)\n",
    "\n",
    "        var_clause_dirmat = var_clause_dirmat_temp\n",
    "        \n",
    "                #print(var_clause_dirmat.shape)\n",
    "        vc_edge_ind, vc_edge_attr = old_dense_to_sparse(torch.tensor(var_clause_dirmat))\n",
    "        #dirvc_edge_ind, dirvc_edge_attr = dense_to_sparse(torch.tensor(var_clause_dirmat))\n",
    "        #print(\"it's undirected: \", is_undirected(vc_edge_ind))\n",
    "        x_var = torch.zeros(num_variables)\n",
    "        x_clause = torch.ones(num_clauses)\n",
    "        x_comb = torch.cat([x_var,x_clause])\n",
    "        #cc_edge_ind, cc_edge_attr = old_dense_to_sparse(torch.tensor(adj_matrix))\n",
    "\n",
    "\n",
    "        graph_object = Data(x= x_comb, edge_index = vc_edge_ind, edge_attr = vc_edge_attr, formula = [formula],  sat=is_sat)\n",
    "\n",
    "#        graph_object = Data(x= x_comb, edge_index = vc_edge_ind, edge_attr = vc_edge_attr, cc_edge_index = cc_edge_ind, cc_edge_att =cc_edge_attr,  formula = [formula],  sat=is_sat)\n",
    "        dataset += [graph_object]\n",
    "        print(\"current graph: \", counter)\n",
    "    return dataset\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_RandomCNFDataset(num_graphs, k, num_variables_low, num_clauses_low, num_variables_high=None, num_clauses_high=None, verbose = True):\n",
    "    dataset=[]\n",
    "    for i in range(num_graphs):\n",
    "        if num_variables_high is None:\n",
    "            num_variables = num_variables_low\n",
    "        else:\n",
    "            num_variables = np.random.randint(num_variables_low, num_variables_high)\n",
    "            \n",
    "        if num_clauses_high is None:\n",
    "            num_clauses = num_clauses_low \n",
    "        else:\n",
    "            num_clauses = np.random.randint(num_clauses_low, num_clauses_high)\n",
    "\n",
    "        num_variables = np.random.randint(num_variables_low, num_variables_high)        \n",
    "        formula = generate_random_kCNF(k, num_variables,num_clauses)\n",
    "\n",
    "        \n",
    "        with Lingeling(bootstrap_with=formula.clauses, with_proof=True) as l:\n",
    "            is_sat = (l.solve())\n",
    "            \n",
    "        num_variables = len(set([np.abs(item) for sublist in (formula.clauses) for item in sublist]))\n",
    "        num_clauses  = len(formula.clauses)\n",
    "\n",
    "        #adj_matrix = get_dependency_matrix(formula)\n",
    "        var_clause_mat, var_clause_dirmat = get_VarClause_matrix(formula,k)\n",
    "    \n",
    "        \n",
    "        # #delete isolated node rows,columns from clause-clause graph and var-clause graph\n",
    "        # adj_matrix = np.delete(adj_matrix,np.where((np.abs(var_clause_dirmat).sum(1)[:formula.nv]==0))[0],axis=0)\n",
    "        # adj_matrix = np.delete(adj_matrix,np.where((np.abs(var_clause_dirmat).sum(1)[:formula.nv]==0))[0],axis=1)\n",
    "\n",
    "\n",
    "        var_clause_dirmat_temp = np.delete(var_clause_dirmat,np.where((np.abs(var_clause_dirmat).sum(1)[:formula.nv]==0))[0],axis=0)\n",
    "        var_clause_dirmat_temp = np.delete(var_clause_dirmat_temp,np.where((np.abs(var_clause_dirmat).sum(1)[:formula.nv]==0))[0],axis=1)\n",
    "\n",
    "        var_clause_dirmat = var_clause_dirmat_temp\n",
    "\n",
    "\n",
    "        #print(var_clause_dirmat.shape)\n",
    "        vc_edge_ind, vc_edge_attr = old_dense_to_sparse(torch.tensor(var_clause_dirmat))\n",
    "        #dirvc_edge_ind, dirvc_edge_attr = dense_to_sparse(torch.tensor(var_clause_dirmat))\n",
    "        #print(\"it's undirected: \", is_undirected(vc_edge_ind))\n",
    "        x_var = torch.zeros(num_variables)\n",
    "        x_clause = torch.ones(num_clauses)\n",
    "        x_comb = torch.cat([x_var,x_clause])\n",
    "        #cc_edge_ind, cc_edge_attr = old_dense_to_sparse(torch.tensor(adj_matrix))\n",
    "        \n",
    "#         if contains_isolated_nodes(vc_edge_ind):\n",
    "#             print(np.where((np.abs(var_clause_dirmat).sum(1)[:formula.nv]==0))[0])\n",
    "#             print(\"contains isolated nodes\")\n",
    "#             breakpoint()\n",
    "        graph_object = Data(x= x_comb, edge_index = vc_edge_ind, edge_attr = vc_edge_attr, formula = [formula],  sat=is_sat)\n",
    "#       graph_object = Data(x= x_comb, edge_index = vc_edge_ind, edge_attr = vc_edge_attr, cc_edge_index = cc_edge_ind, cc_edge_att =cc_edge_attr,  formula = [formula],  sat=is_sat)\n",
    "\n",
    "        dataset += [graph_object]\n",
    "        if verbose:\n",
    "            print(\"current graph: \", i)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dimacs_directory(directory):\n",
    "    directory_contents = os.listdir(directory)\n",
    "    dataset_formulas = []\n",
    "    #print(directory_contents)\n",
    "    for k in range(len(directory_contents)):\n",
    "        if \"txt\" in directory_contents[k].split()[0]:\n",
    "            formula = CNF(from_file= directory + '/' +directory_contents[k])\n",
    "            #print(formula)\n",
    "            dataset_formulas += [formula]  \n",
    "    return dataset_formulas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATE OR LOAD DATASET HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current graph:  0\n",
      "current graph:  1\n",
      "current graph:  2\n",
      "current graph:  3\n",
      "current graph:  4\n",
      "current graph:  5\n",
      "current graph:  6\n",
      "current graph:  7\n",
      "current graph:  8\n",
      "current graph:  9\n",
      "current graph:  10\n",
      "current graph:  11\n",
      "current graph:  12\n",
      "current graph:  13\n",
      "current graph:  14\n",
      "current graph:  15\n",
      "current graph:  16\n",
      "current graph:  17\n",
      "current graph:  18\n",
      "current graph:  19\n",
      "current graph:  20\n",
      "current graph:  21\n",
      "current graph:  22\n",
      "current graph:  23\n",
      "current graph:  24\n",
      "current graph:  25\n",
      "current graph:  26\n",
      "current graph:  27\n",
      "current graph:  28\n",
      "current graph:  29\n",
      "current graph:  30\n",
      "current graph:  31\n",
      "current graph:  32\n",
      "current graph:  33\n",
      "current graph:  34\n",
      "current graph:  35\n",
      "current graph:  36\n",
      "current graph:  37\n",
      "current graph:  38\n",
      "current graph:  39\n",
      "current graph:  40\n",
      "current graph:  41\n",
      "current graph:  42\n",
      "current graph:  43\n",
      "current graph:  44\n",
      "current graph:  45\n",
      "current graph:  46\n",
      "current graph:  47\n",
      "current graph:  48\n",
      "current graph:  49\n",
      "current graph:  50\n",
      "current graph:  51\n",
      "current graph:  52\n",
      "current graph:  53\n",
      "current graph:  54\n",
      "current graph:  55\n",
      "current graph:  56\n",
      "current graph:  57\n",
      "current graph:  58\n",
      "current graph:  59\n",
      "current graph:  60\n",
      "current graph:  61\n",
      "current graph:  62\n",
      "current graph:  63\n",
      "current graph:  64\n",
      "current graph:  65\n",
      "current graph:  66\n",
      "current graph:  67\n",
      "current graph:  68\n",
      "current graph:  69\n",
      "current graph:  70\n",
      "current graph:  71\n",
      "current graph:  72\n",
      "current graph:  73\n",
      "current graph:  74\n",
      "current graph:  75\n",
      "current graph:  76\n",
      "current graph:  77\n",
      "current graph:  78\n",
      "current graph:  79\n",
      "current graph:  80\n",
      "current graph:  81\n",
      "current graph:  82\n",
      "current graph:  83\n",
      "current graph:  84\n",
      "current graph:  85\n",
      "current graph:  86\n",
      "current graph:  87\n",
      "current graph:  88\n",
      "current graph:  89\n",
      "current graph:  90\n",
      "current graph:  91\n",
      "current graph:  92\n",
      "current graph:  93\n",
      "current graph:  94\n",
      "current graph:  95\n",
      "current graph:  96\n",
      "current graph:  97\n",
      "current graph:  98\n",
      "current graph:  99\n",
      "current graph:  100\n",
      "current graph:  101\n",
      "current graph:  102\n",
      "current graph:  103\n",
      "current graph:  104\n",
      "current graph:  105\n",
      "current graph:  106\n",
      "current graph:  107\n",
      "current graph:  108\n",
      "current graph:  109\n",
      "current graph:  110\n",
      "current graph:  111\n",
      "current graph:  112\n",
      "current graph:  113\n",
      "current graph:  114\n",
      "current graph:  115\n",
      "current graph:  116\n",
      "current graph:  117\n",
      "current graph:  118\n",
      "current graph:  119\n",
      "current graph:  120\n",
      "current graph:  121\n",
      "current graph:  122\n",
      "current graph:  123\n",
      "current graph:  124\n",
      "current graph:  125\n",
      "current graph:  126\n",
      "current graph:  127\n",
      "current graph:  128\n",
      "current graph:  129\n",
      "current graph:  130\n",
      "current graph:  131\n",
      "current graph:  132\n",
      "current graph:  133\n",
      "current graph:  134\n",
      "current graph:  135\n",
      "current graph:  136\n",
      "current graph:  137\n",
      "current graph:  138\n",
      "current graph:  139\n",
      "current graph:  140\n",
      "current graph:  141\n",
      "current graph:  142\n",
      "current graph:  143\n",
      "current graph:  144\n",
      "current graph:  145\n",
      "current graph:  146\n",
      "current graph:  147\n",
      "current graph:  148\n",
      "current graph:  149\n",
      "current graph:  150\n",
      "current graph:  151\n",
      "current graph:  152\n",
      "current graph:  153\n",
      "current graph:  154\n",
      "current graph:  155\n",
      "current graph:  156\n",
      "current graph:  157\n",
      "current graph:  158\n",
      "current graph:  159\n",
      "current graph:  160\n",
      "current graph:  161\n",
      "current graph:  162\n",
      "current graph:  163\n",
      "current graph:  164\n",
      "current graph:  165\n",
      "current graph:  166\n",
      "current graph:  167\n",
      "current graph:  168\n",
      "current graph:  169\n",
      "current graph:  170\n",
      "current graph:  171\n",
      "current graph:  172\n",
      "current graph:  173\n",
      "current graph:  174\n",
      "current graph:  175\n",
      "current graph:  176\n",
      "current graph:  177\n",
      "current graph:  178\n",
      "current graph:  179\n",
      "current graph:  180\n",
      "current graph:  181\n",
      "current graph:  182\n",
      "current graph:  183\n",
      "current graph:  184\n",
      "current graph:  185\n",
      "current graph:  186\n",
      "current graph:  187\n",
      "current graph:  188\n",
      "current graph:  189\n",
      "current graph:  190\n",
      "current graph:  191\n",
      "current graph:  192\n",
      "current graph:  193\n",
      "current graph:  194\n",
      "current graph:  195\n",
      "current graph:  196\n",
      "current graph:  197\n",
      "current graph:  198\n",
      "current graph:  199\n",
      "current graph:  200\n",
      "current graph:  201\n",
      "current graph:  202\n",
      "current graph:  203\n",
      "current graph:  204\n",
      "current graph:  205\n",
      "current graph:  206\n",
      "current graph:  207\n",
      "current graph:  208\n",
      "current graph:  209\n",
      "current graph:  210\n",
      "current graph:  211\n",
      "current graph:  212\n",
      "current graph:  213\n",
      "current graph:  214\n",
      "current graph:  215\n",
      "current graph:  216\n",
      "current graph:  217\n",
      "current graph:  218\n",
      "current graph:  219\n",
      "current graph:  220\n",
      "current graph:  221\n",
      "current graph:  222\n",
      "current graph:  223\n",
      "current graph:  224\n",
      "current graph:  225\n",
      "current graph:  226\n",
      "current graph:  227\n",
      "current graph:  228\n",
      "current graph:  229\n",
      "current graph:  230\n",
      "current graph:  231\n",
      "current graph:  232\n",
      "current graph:  233\n",
      "current graph:  234\n",
      "current graph:  235\n",
      "current graph:  236\n",
      "current graph:  237\n",
      "current graph:  238\n",
      "current graph:  239\n",
      "current graph:  240\n",
      "current graph:  241\n",
      "current graph:  242\n",
      "current graph:  243\n",
      "current graph:  244\n",
      "current graph:  245\n",
      "current graph:  246\n",
      "current graph:  247\n",
      "current graph:  248\n",
      "current graph:  249\n",
      "current graph:  250\n",
      "current graph:  251\n",
      "current graph:  252\n",
      "current graph:  253\n",
      "current graph:  254\n",
      "current graph:  255\n",
      "current graph:  256\n",
      "current graph:  257\n",
      "current graph:  258\n",
      "current graph:  259\n",
      "current graph:  260\n",
      "current graph:  261\n",
      "current graph:  262\n",
      "current graph:  263\n",
      "current graph:  264\n",
      "current graph:  265\n",
      "current graph:  266\n",
      "current graph:  267\n",
      "current graph:  268\n",
      "current graph:  269\n",
      "current graph:  270\n",
      "current graph:  271\n",
      "current graph:  272\n",
      "current graph:  273\n",
      "current graph:  274\n",
      "current graph:  275\n",
      "current graph:  276\n",
      "current graph:  277\n",
      "current graph:  278\n",
      "current graph:  279\n",
      "current graph:  280\n",
      "current graph:  281\n",
      "current graph:  282\n",
      "current graph:  283\n",
      "current graph:  284\n",
      "current graph:  285\n",
      "current graph:  286\n",
      "current graph:  287\n",
      "current graph:  288\n",
      "current graph:  289\n",
      "current graph:  290\n",
      "current graph:  291\n",
      "current graph:  292\n",
      "current graph:  293\n",
      "current graph:  294\n",
      "current graph:  295\n",
      "current graph:  296\n",
      "current graph:  297\n",
      "current graph:  298\n",
      "current graph:  299\n",
      "current graph:  300\n",
      "current graph:  301\n",
      "current graph:  302\n",
      "current graph:  303\n",
      "current graph:  304\n",
      "current graph:  305\n",
      "current graph:  306\n",
      "current graph:  307\n",
      "current graph:  308\n",
      "current graph:  309\n",
      "current graph:  310\n",
      "current graph:  311\n",
      "current graph:  312\n",
      "current graph:  313\n",
      "current graph:  314\n",
      "current graph:  315\n",
      "current graph:  316\n",
      "current graph:  317\n",
      "current graph:  318\n",
      "current graph:  319\n",
      "current graph:  320\n",
      "current graph:  321\n",
      "current graph:  322\n",
      "current graph:  323\n",
      "current graph:  324\n",
      "current graph:  325\n",
      "current graph:  326\n",
      "current graph:  327\n",
      "current graph:  328\n",
      "current graph:  329\n",
      "current graph:  330\n",
      "current graph:  331\n",
      "current graph:  332\n",
      "current graph:  333\n",
      "current graph:  334\n",
      "current graph:  335\n",
      "current graph:  336\n",
      "current graph:  337\n",
      "current graph:  338\n",
      "current graph:  339\n",
      "current graph:  340\n",
      "current graph:  341\n",
      "current graph:  342\n",
      "current graph:  343\n",
      "current graph:  344\n",
      "current graph:  345\n",
      "current graph:  346\n",
      "current graph:  347\n",
      "current graph:  348\n",
      "current graph:  349\n",
      "current graph:  350\n",
      "current graph:  351\n",
      "current graph:  352\n",
      "current graph:  353\n",
      "current graph:  354\n",
      "current graph:  355\n",
      "current graph:  356\n",
      "current graph:  357\n",
      "current graph:  358\n",
      "current graph:  359\n",
      "current graph:  360\n",
      "current graph:  361\n",
      "current graph:  362\n",
      "current graph:  363\n",
      "current graph:  364\n",
      "current graph:  365\n",
      "current graph:  366\n",
      "current graph:  367\n",
      "current graph:  368\n",
      "current graph:  369\n",
      "current graph:  370\n",
      "current graph:  371\n",
      "current graph:  372\n",
      "current graph:  373\n",
      "current graph:  374\n",
      "current graph:  375\n",
      "current graph:  376\n",
      "current graph:  377\n",
      "current graph:  378\n",
      "current graph:  379\n",
      "current graph:  380\n",
      "current graph:  381\n",
      "current graph:  382\n",
      "current graph:  383\n",
      "current graph:  384\n",
      "current graph:  385\n",
      "current graph:  386\n",
      "current graph:  387\n",
      "current graph:  388\n",
      "current graph:  389\n",
      "current graph:  390\n",
      "current graph:  391\n",
      "current graph:  392\n",
      "current graph:  393\n",
      "current graph:  394\n",
      "current graph:  395\n",
      "current graph:  396\n",
      "current graph:  397\n",
      "current graph:  398\n",
      "current graph:  399\n",
      "current graph:  400\n",
      "current graph:  401\n",
      "current graph:  402\n",
      "current graph:  403\n",
      "current graph:  404\n",
      "current graph:  405\n",
      "current graph:  406\n",
      "current graph:  407\n",
      "current graph:  408\n",
      "current graph:  409\n",
      "current graph:  410\n",
      "current graph:  411\n",
      "current graph:  412\n",
      "current graph:  413\n",
      "current graph:  414\n",
      "current graph:  415\n",
      "current graph:  416\n",
      "current graph:  417\n",
      "current graph:  418\n",
      "current graph:  419\n",
      "current graph:  420\n",
      "current graph:  421\n",
      "current graph:  422\n",
      "current graph:  423\n",
      "current graph:  424\n",
      "current graph:  425\n",
      "current graph:  426\n",
      "current graph:  427\n",
      "current graph:  428\n",
      "current graph:  429\n",
      "current graph:  430\n",
      "current graph:  431\n",
      "current graph:  432\n",
      "current graph:  433\n",
      "current graph:  434\n",
      "current graph:  435\n",
      "current graph:  436\n",
      "current graph:  437\n",
      "current graph:  438\n",
      "current graph:  439\n",
      "current graph:  440\n",
      "current graph:  441\n",
      "current graph:  442\n",
      "current graph:  443\n",
      "current graph:  444\n",
      "current graph:  445\n",
      "current graph:  446\n",
      "current graph:  447\n",
      "current graph:  448\n",
      "current graph:  449\n",
      "current graph:  450\n",
      "current graph:  451\n",
      "current graph:  452\n",
      "current graph:  453\n",
      "current graph:  454\n",
      "current graph:  455\n",
      "current graph:  456\n",
      "current graph:  457\n",
      "current graph:  458\n",
      "current graph:  459\n",
      "current graph:  460\n",
      "current graph:  461\n",
      "current graph:  462\n",
      "current graph:  463\n",
      "current graph:  464\n",
      "current graph:  465\n",
      "current graph:  466\n",
      "current graph:  467\n",
      "current graph:  468\n",
      "current graph:  469\n",
      "current graph:  470\n",
      "current graph:  471\n",
      "current graph:  472\n",
      "current graph:  473\n",
      "current graph:  474\n",
      "current graph:  475\n",
      "current graph:  476\n",
      "current graph:  477\n",
      "current graph:  478\n",
      "current graph:  479\n",
      "current graph:  480\n",
      "current graph:  481\n",
      "current graph:  482\n",
      "current graph:  483\n",
      "current graph:  484\n",
      "current graph:  485\n",
      "current graph:  486\n",
      "current graph:  487\n",
      "current graph:  488\n",
      "current graph:  489\n",
      "current graph:  490\n",
      "current graph:  491\n",
      "current graph:  492\n",
      "current graph:  493\n",
      "current graph:  494\n",
      "current graph:  495\n",
      "current graph:  496\n",
      "current graph:  497\n",
      "current graph:  498\n",
      "current graph:  499\n",
      "current graph:  500\n",
      "current graph:  501\n",
      "current graph:  502\n",
      "current graph:  503\n",
      "current graph:  504\n",
      "current graph:  505\n",
      "current graph:  506\n",
      "current graph:  507\n",
      "current graph:  508\n",
      "current graph:  509\n",
      "current graph:  510\n",
      "current graph:  511\n",
      "current graph:  512\n",
      "current graph:  513\n",
      "current graph:  514\n",
      "current graph:  515\n",
      "current graph:  516\n",
      "current graph:  517\n",
      "current graph:  518\n",
      "current graph:  519\n",
      "current graph:  520\n",
      "current graph:  521\n",
      "current graph:  522\n",
      "current graph:  523\n",
      "current graph:  524\n",
      "current graph:  525\n",
      "current graph:  526\n",
      "current graph:  527\n",
      "current graph:  528\n",
      "current graph:  529\n",
      "current graph:  530\n",
      "current graph:  531\n",
      "current graph:  532\n",
      "current graph:  533\n",
      "current graph:  534\n",
      "current graph:  535\n",
      "current graph:  536\n",
      "current graph:  537\n",
      "current graph:  538\n",
      "current graph:  539\n",
      "current graph:  540\n",
      "current graph:  541\n",
      "current graph:  542\n",
      "current graph:  543\n",
      "current graph:  544\n",
      "current graph:  545\n",
      "current graph:  546\n",
      "current graph:  547\n",
      "current graph:  548\n",
      "current graph:  549\n",
      "current graph:  550\n",
      "current graph:  551\n",
      "current graph:  552\n",
      "current graph:  553\n",
      "current graph:  554\n",
      "current graph:  555\n",
      "current graph:  556\n",
      "current graph:  557\n",
      "current graph:  558\n",
      "current graph:  559\n",
      "current graph:  560\n",
      "current graph:  561\n",
      "current graph:  562\n",
      "current graph:  563\n",
      "current graph:  564\n",
      "current graph:  565\n",
      "current graph:  566\n",
      "current graph:  567\n",
      "current graph:  568\n",
      "current graph:  569\n",
      "current graph:  570\n",
      "current graph:  571\n",
      "current graph:  572\n",
      "current graph:  573\n",
      "current graph:  574\n",
      "current graph:  575\n",
      "current graph:  576\n",
      "current graph:  577\n",
      "current graph:  578\n",
      "current graph:  579\n",
      "current graph:  580\n",
      "current graph:  581\n",
      "current graph:  582\n",
      "current graph:  583\n",
      "current graph:  584\n",
      "current graph:  585\n",
      "current graph:  586\n",
      "current graph:  587\n",
      "current graph:  588\n",
      "current graph:  589\n",
      "current graph:  590\n",
      "current graph:  591\n",
      "current graph:  592\n",
      "current graph:  593\n",
      "current graph:  594\n",
      "current graph:  595\n",
      "current graph:  596\n",
      "current graph:  597\n",
      "current graph:  598\n",
      "current graph:  599\n",
      "current graph:  600\n",
      "current graph:  601\n",
      "current graph:  602\n",
      "current graph:  603\n",
      "current graph:  604\n",
      "current graph:  605\n",
      "current graph:  606\n",
      "current graph:  607\n",
      "current graph:  608\n",
      "current graph:  609\n",
      "current graph:  610\n",
      "current graph:  611\n",
      "current graph:  612\n",
      "current graph:  613\n",
      "current graph:  614\n",
      "current graph:  615\n",
      "current graph:  616\n",
      "current graph:  617\n",
      "current graph:  618\n",
      "current graph:  619\n",
      "current graph:  620\n",
      "current graph:  621\n",
      "current graph:  622\n",
      "current graph:  623\n",
      "current graph:  624\n",
      "current graph:  625\n",
      "current graph:  626\n",
      "current graph:  627\n",
      "current graph:  628\n",
      "current graph:  629\n",
      "current graph:  630\n",
      "current graph:  631\n",
      "current graph:  632\n",
      "current graph:  633\n",
      "current graph:  634\n",
      "current graph:  635\n",
      "current graph:  636\n",
      "current graph:  637\n",
      "current graph:  638\n",
      "current graph:  639\n",
      "current graph:  640\n",
      "current graph:  641\n",
      "current graph:  642\n",
      "current graph:  643\n",
      "current graph:  644\n",
      "current graph:  645\n",
      "current graph:  646\n",
      "current graph:  647\n",
      "current graph:  648\n",
      "current graph:  649\n",
      "current graph:  650\n",
      "current graph:  651\n",
      "current graph:  652\n",
      "current graph:  653\n",
      "current graph:  654\n",
      "current graph:  655\n",
      "current graph:  656\n",
      "current graph:  657\n",
      "current graph:  658\n",
      "current graph:  659\n",
      "current graph:  660\n",
      "current graph:  661\n",
      "current graph:  662\n",
      "current graph:  663\n",
      "current graph:  664\n",
      "current graph:  665\n",
      "current graph:  666\n",
      "current graph:  667\n",
      "current graph:  668\n",
      "current graph:  669\n",
      "current graph:  670\n",
      "current graph:  671\n",
      "current graph:  672\n",
      "current graph:  673\n",
      "current graph:  674\n",
      "current graph:  675\n",
      "current graph:  676\n",
      "current graph:  677\n",
      "current graph:  678\n",
      "current graph:  679\n",
      "current graph:  680\n",
      "current graph:  681\n",
      "current graph:  682\n",
      "current graph:  683\n",
      "current graph:  684\n",
      "current graph:  685\n",
      "current graph:  686\n",
      "current graph:  687\n",
      "current graph:  688\n",
      "current graph:  689\n",
      "current graph:  690\n",
      "current graph:  691\n",
      "current graph:  692\n",
      "current graph:  693\n",
      "current graph:  694\n",
      "current graph:  695\n",
      "current graph:  696\n",
      "current graph:  697\n",
      "current graph:  698\n",
      "current graph:  699\n",
      "current graph:  700\n",
      "current graph:  701\n",
      "current graph:  702\n",
      "current graph:  703\n",
      "current graph:  704\n",
      "current graph:  705\n",
      "current graph:  706\n",
      "current graph:  707\n",
      "current graph:  708\n",
      "current graph:  709\n",
      "current graph:  710\n",
      "current graph:  711\n",
      "current graph:  712\n",
      "current graph:  713\n",
      "current graph:  714\n",
      "current graph:  715\n",
      "current graph:  716\n",
      "current graph:  717\n",
      "current graph:  718\n",
      "current graph:  719\n",
      "current graph:  720\n",
      "current graph:  721\n",
      "current graph:  722\n",
      "current graph:  723\n",
      "current graph:  724\n",
      "current graph:  725\n",
      "current graph:  726\n",
      "current graph:  727\n",
      "current graph:  728\n",
      "current graph:  729\n",
      "current graph:  730\n",
      "current graph:  731\n",
      "current graph:  732\n",
      "current graph:  733\n",
      "current graph:  734\n",
      "current graph:  735\n",
      "current graph:  736\n",
      "current graph:  737\n",
      "current graph:  738\n",
      "current graph:  739\n",
      "current graph:  740\n",
      "current graph:  741\n",
      "current graph:  742\n",
      "current graph:  743\n",
      "current graph:  744\n",
      "current graph:  745\n",
      "current graph:  746\n",
      "current graph:  747\n",
      "current graph:  748\n",
      "current graph:  749\n",
      "current graph:  750\n",
      "current graph:  751\n",
      "current graph:  752\n",
      "current graph:  753\n",
      "current graph:  754\n",
      "current graph:  755\n",
      "current graph:  756\n",
      "current graph:  757\n",
      "current graph:  758\n",
      "current graph:  759\n",
      "current graph:  760\n",
      "current graph:  761\n",
      "current graph:  762\n",
      "current graph:  763\n",
      "current graph:  764\n",
      "current graph:  765\n",
      "current graph:  766\n",
      "current graph:  767\n",
      "current graph:  768\n",
      "current graph:  769\n",
      "current graph:  770\n",
      "current graph:  771\n",
      "current graph:  772\n",
      "current graph:  773\n",
      "current graph:  774\n",
      "current graph:  775\n",
      "current graph:  776\n",
      "current graph:  777\n",
      "current graph:  778\n",
      "current graph:  779\n",
      "current graph:  780\n",
      "current graph:  781\n",
      "current graph:  782\n",
      "current graph:  783\n",
      "current graph:  784\n",
      "current graph:  785\n",
      "current graph:  786\n",
      "current graph:  787\n",
      "current graph:  788\n",
      "current graph:  789\n",
      "current graph:  790\n",
      "current graph:  791\n",
      "current graph:  792\n",
      "current graph:  793\n",
      "current graph:  794\n",
      "current graph:  795\n",
      "current graph:  796\n",
      "current graph:  797\n",
      "current graph:  798\n",
      "current graph:  799\n",
      "current graph:  800\n",
      "current graph:  801\n",
      "current graph:  802\n",
      "current graph:  803\n",
      "current graph:  804\n",
      "current graph:  805\n",
      "current graph:  806\n",
      "current graph:  807\n",
      "current graph:  808\n",
      "current graph:  809\n",
      "current graph:  810\n",
      "current graph:  811\n",
      "current graph:  812\n",
      "current graph:  813\n",
      "current graph:  814\n",
      "current graph:  815\n",
      "current graph:  816\n",
      "current graph:  817\n",
      "current graph:  818\n",
      "current graph:  819\n",
      "current graph:  820\n",
      "current graph:  821\n",
      "current graph:  822\n",
      "current graph:  823\n",
      "current graph:  824\n",
      "current graph:  825\n",
      "current graph:  826\n",
      "current graph:  827\n",
      "current graph:  828\n",
      "current graph:  829\n",
      "current graph:  830\n",
      "current graph:  831\n",
      "current graph:  832\n",
      "current graph:  833\n",
      "current graph:  834\n",
      "current graph:  835\n",
      "current graph:  836\n",
      "current graph:  837\n",
      "current graph:  838\n",
      "current graph:  839\n",
      "current graph:  840\n",
      "current graph:  841\n",
      "current graph:  842\n",
      "current graph:  843\n",
      "current graph:  844\n",
      "current graph:  845\n",
      "current graph:  846\n",
      "current graph:  847\n",
      "current graph:  848\n",
      "current graph:  849\n",
      "current graph:  850\n",
      "current graph:  851\n",
      "current graph:  852\n",
      "current graph:  853\n",
      "current graph:  854\n",
      "current graph:  855\n",
      "current graph:  856\n",
      "current graph:  857\n",
      "current graph:  858\n",
      "current graph:  859\n",
      "current graph:  860\n",
      "current graph:  861\n",
      "current graph:  862\n",
      "current graph:  863\n",
      "current graph:  864\n",
      "current graph:  865\n",
      "current graph:  866\n",
      "current graph:  867\n",
      "current graph:  868\n",
      "current graph:  869\n",
      "current graph:  870\n",
      "current graph:  871\n",
      "current graph:  872\n",
      "current graph:  873\n",
      "current graph:  874\n",
      "current graph:  875\n",
      "current graph:  876\n",
      "current graph:  877\n",
      "current graph:  878\n",
      "current graph:  879\n",
      "current graph:  880\n",
      "current graph:  881\n",
      "current graph:  882\n",
      "current graph:  883\n",
      "current graph:  884\n",
      "current graph:  885\n",
      "current graph:  886\n",
      "current graph:  887\n",
      "current graph:  888\n",
      "current graph:  889\n",
      "current graph:  890\n",
      "current graph:  891\n",
      "current graph:  892\n",
      "current graph:  893\n",
      "current graph:  894\n",
      "current graph:  895\n",
      "current graph:  896\n",
      "current graph:  897\n",
      "current graph:  898\n",
      "current graph:  899\n",
      "current graph:  900\n",
      "current graph:  901\n",
      "current graph:  902\n",
      "current graph:  903\n",
      "current graph:  904\n",
      "current graph:  905\n",
      "current graph:  906\n",
      "current graph:  907\n",
      "current graph:  908\n",
      "current graph:  909\n",
      "current graph:  910\n",
      "current graph:  911\n",
      "current graph:  912\n",
      "current graph:  913\n",
      "current graph:  914\n",
      "current graph:  915\n",
      "current graph:  916\n",
      "current graph:  917\n",
      "current graph:  918\n",
      "current graph:  919\n",
      "current graph:  920\n",
      "current graph:  921\n",
      "current graph:  922\n",
      "current graph:  923\n",
      "current graph:  924\n",
      "current graph:  925\n",
      "current graph:  926\n",
      "current graph:  927\n",
      "current graph:  928\n",
      "current graph:  929\n",
      "current graph:  930\n",
      "current graph:  931\n",
      "current graph:  932\n",
      "current graph:  933\n",
      "current graph:  934\n",
      "current graph:  935\n",
      "current graph:  936\n",
      "current graph:  937\n",
      "current graph:  938\n",
      "current graph:  939\n",
      "current graph:  940\n",
      "current graph:  941\n",
      "current graph:  942\n",
      "current graph:  943\n",
      "current graph:  944\n",
      "current graph:  945\n",
      "current graph:  946\n",
      "current graph:  947\n",
      "current graph:  948\n",
      "current graph:  949\n",
      "current graph:  950\n",
      "current graph:  951\n",
      "current graph:  952\n",
      "current graph:  953\n",
      "current graph:  954\n",
      "current graph:  955\n",
      "current graph:  956\n",
      "current graph:  957\n",
      "current graph:  958\n",
      "current graph:  959\n",
      "current graph:  960\n",
      "current graph:  961\n",
      "current graph:  962\n",
      "current graph:  963\n",
      "current graph:  964\n",
      "current graph:  965\n",
      "current graph:  966\n",
      "current graph:  967\n",
      "current graph:  968\n",
      "current graph:  969\n",
      "current graph:  970\n",
      "current graph:  971\n",
      "current graph:  972\n",
      "current graph:  973\n",
      "current graph:  974\n",
      "current graph:  975\n",
      "current graph:  976\n",
      "current graph:  977\n",
      "current graph:  978\n",
      "current graph:  979\n",
      "current graph:  980\n",
      "current graph:  981\n",
      "current graph:  982\n",
      "current graph:  983\n",
      "current graph:  984\n",
      "current graph:  985\n",
      "current graph:  986\n",
      "current graph:  987\n",
      "current graph:  988\n",
      "current graph:  989\n",
      "current graph:  990\n",
      "current graph:  991\n",
      "current graph:  992\n",
      "current graph:  993\n",
      "current graph:  994\n",
      "current graph:  995\n",
      "current graph:  996\n",
      "current graph:  997\n",
      "current graph:  998\n",
      "current graph:  999\n"
     ]
    }
   ],
   "source": [
    "parent_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "my_data = read_dimacs_directory(parent_path+'/datasets/dimacs_400_random/')\n",
    "test_dataset_torch = generate_dimacs_CNFDataset(my_data,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decide on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pytorch_memlab import profile, mem_reporter\n",
    "#@profile\n",
    "class Erdos_MPNN(torch.nn.Module):\n",
    "    def __init__(self, num_layers, hidden1, hidden2,  num_iterations = 1):\n",
    "        super(Erdos_MPNN, self).__init__()\n",
    "        self.hidden1 = hidden1\n",
    "        self.hidden2 = hidden2\n",
    "        self.momentum = 0.1\n",
    "        self.num_iterations = num_iterations\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.numlayers = num_layers\n",
    "        self.heads = 1\n",
    "        self.concat = True        \n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bn = BN(self.heads*self.hidden1, momentum=self.momentum)\n",
    "        for i in range(num_layers-1):\n",
    "            self.bns.append(BN(self.heads*self.hidden1, momentum=self.momentum))\n",
    "\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()        \n",
    "        self.bn1 = BN(self.heads*self.hidden1)\n",
    "       \n",
    "        self.conv  = GatedGraphConv(self.hidden1,self.numlayers)\n",
    "        \n",
    "\n",
    "        self.conv1 = GINEConv(Sequential(Linear(self.hidden2,  self.heads*self.hidden1),\n",
    "            ReLU(),\n",
    "            Linear( self.heads*self.hidden1,  self.heads*self.hidden1),\n",
    "            ReLU(),\n",
    "            BN(self.heads*self.hidden1, momentum=self.momentum),\n",
    "        ),train_eps=False)\n",
    "        \n",
    "        self.x_lin_2 = Linear(self.hidden1,1)\n",
    "        self.x_lin_1 = Linear(self.hidden1,self.hidden1)\n",
    "        \n",
    "        self.x_batchnorm = BN(self.hidden1)\n",
    "        if self.concat:\n",
    "            self.lin1 = Linear(self.heads*self.hidden1, self.hidden1)\n",
    "        else:\n",
    "            self.lin1 = Linear(self.hidden1, self.hidden1)\n",
    "        self.lin2 = Linear(self.hidden1, 1)\n",
    "        self.gnorm = graph_size_norm.GraphSizeNorm()\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        #self.conv_alt.reset_parameters()\n",
    "        #self.conv_alt_rec.reset_parameters()\n",
    "        self.conv.reset_parameters()\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "            \n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "            \n",
    "        self.bn1.reset_parameters()\n",
    "        self.lin1.reset_parameters()\n",
    "        self.lin2.reset_parameters()\n",
    "       # self.x_lin_1.reset_parameters()\n",
    "        #self.x_lin_2.reset_parameters()\n",
    "#\n",
    "        # self.x_conv_probs.reset_parameters()\n",
    "        # self.x_conv_degs.reset_parameters()\n",
    "\n",
    "        \n",
    "        #self.x_conv_2.reset_parameters()\n",
    "        self.x_batchnorm.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        x_index = data.x\n",
    "        batch = data.batch\n",
    "        num_graphs = batch.max().item() + 1\n",
    "\n",
    "#         print(\"degs shape\", degs.shape)\n",
    "#         print(\"data.x shape \", data.x.shape)\n",
    "        \n",
    "        #directed edge index\n",
    "        #print(is_undirected(data.edge_index))\n",
    "        d_row, d_col = data.edge_index.detach()\n",
    "        edge_attr = data.edge_attr.detach()\n",
    "        \n",
    "        pos_assoc = edge_attr*((edge_attr>0)*1.)\n",
    "        neg_assoc = edge_attr*((edge_attr<0)*1.)\n",
    "        \n",
    "        #make undirected\n",
    "        edge_index = torch.cat([data.edge_index,data.edge_index[[1,0],:]],dim=1)\n",
    "        edge_attr = torch.cat([edge_attr.unsqueeze(-1), edge_attr.unsqueeze(-1)],dim=0)\n",
    "\n",
    "        \n",
    "        select_clauses = (data.x==1)\n",
    "        select_variables = (data.x==0)\n",
    "\n",
    "        #CREATE UNDIRECTED EDGE_INDEX\n",
    "        row, col = edge_index\n",
    "        \n",
    "        #DANGEROUS\n",
    "        degs = degree(row)\n",
    "        x = degs*1.\n",
    "        \n",
    "\n",
    "        #other stuff\n",
    "        total_num_edges = edge_index.shape[1]\n",
    "        N_size = x.shape[0]\n",
    "        \n",
    "        # #positive and negative degrees of each node\n",
    "        posdeg= scatter(pos_assoc,d_col, dim=0, dim_size=data.x.shape[0], reduce=\"sum\")+scatter(pos_assoc,d_row, dim=0, dim_size=data.x.shape[0], reduce=\"sum\")\n",
    "        negdeg= scatter(neg_assoc,d_col, dim=0, dim_size=data.x.shape[0], reduce=\"sum\")+scatter(neg_assoc,d_row, dim=0, dim_size=data.x.shape[0], reduce=\"sum\")\n",
    "        \n",
    "\n",
    "        x = torch.cat([posdeg.unsqueeze(-1), negdeg.unsqueeze(-1)],dim=1)*1.\n",
    "        x = x.float()\n",
    "\n",
    "        ##UNSQUEEZED\n",
    "        #x = F.leaky_relu(self.conv1(x.unsqueeze(-1), edge_index))# +x\n",
    "        adjusted_ea = torch.repeat_interleave(edge_attr,self.hidden2,1)\n",
    "        adjusted_ea = adjusted_ea.float()\n",
    "        x = x.squeeze(-1)\n",
    "        x = x.float()\n",
    "        \n",
    "        iterations = 0\n",
    "        total_loss = []\n",
    "        while (iterations < self.num_iterations):\n",
    "            \n",
    "            if(iterations>0):\n",
    "                x = torch.cat([posdeg.unsqueeze(-1), negdeg.unsqueeze(-1)],dim=1)*1.\n",
    "                x = x.float()\n",
    "        \n",
    "                recurr =  torch.repeat_interleave(transformed_probs_comp.unsqueeze(-1),self.hidden2,1)\n",
    "                recurr_activ =  F.leaky_relu(self.conv_alt_rec(recurr, edge_index,adjusted_ea))\n",
    "                x = F.leaky_relu(self.conv_alt(x, edge_index,adjusted_ea))  * recurr_activ\n",
    "                                 \n",
    "            else:\n",
    "                #FIRST CONVO\n",
    "                x = F.leaky_relu(self.conv1(x, edge_index,adjusted_ea))# +x\n",
    "\n",
    "            x_1 = x.clone()\n",
    "            \n",
    "            #ADJUST EDGE \n",
    "            adjusted_ea_2 = torch.repeat_interleave(edge_attr.unsqueeze(-1), self.hidden1,1)\n",
    "            adjusted_ea_2 = (adjusted_ea_2.squeeze(-1)).float()\n",
    "\n",
    "\n",
    "            x =  x+F.leaky_relu(self.conv(x, edge_index,edge_attr.float())) #+ x_1 GRU MODE\n",
    "\n",
    "            x =  F.leaky_relu(self.lin1(x)) \n",
    "            x = F.leaky_relu(self.lin2(x)) \n",
    "\n",
    "            probs = torch.sigmoid(x)*0.999990 + 0.000001 \n",
    "            probs = probs.squeeze(-1) #shape: x\n",
    "            probs_backup = probs.clone()\n",
    "\n",
    "            #sanity check\n",
    "            #WARNING EDGE ATTR!= DATA.EDGE_ATTR\n",
    "            pos_neg_index = (data.edge_attr==-1)*1.\n",
    "            test_probs = torch.ones_like(probs)*0.25\n",
    "            test_probs = test_probs.squeeze(-1)\n",
    "            test_msg = (1-pos_neg_index) *(1- test_probs[d_row]) + (pos_neg_index)*(test_probs[d_row])\n",
    "            test_msg_c = (pos_neg_index) *(1- test_probs[d_row]) + (1-pos_neg_index)*(test_probs[d_row])\n",
    "\n",
    "            msg = pos_neg_index *(1- probs[d_row]) + (1-pos_neg_index)*(probs[d_row])\n",
    "            comp_msg = pos_neg_index *( probs[d_row]) + (1-pos_neg_index)*(1-probs[d_row])\n",
    "            pre_exp_comp = scatter(torch.log(comp_msg),d_col,dim=0, reduce=\"sum\")\n",
    "            pre_exp = scatter(torch.log(msg),d_col,dim=0, reduce=\"sum\")\n",
    "            transformed_probs = torch.exp(pre_exp)\n",
    "            transformed_probs_comp = torch.exp(pre_exp_comp)\n",
    "            clause_probs = transformed_probs.squeeze(-1)*((x_index==1)*1.)\n",
    "            clause_probs_comp = transformed_probs_comp.squeeze(-1)*((x_index==1)*1.) #shape: x\n",
    "            var_probs = probs[data.x==0].detach()\n",
    "\n",
    "            loss_comp = scatter(clause_probs, batch, dim=0 , reduce=\"sum\") #expected_loss#*normalize\n",
    "            loss = scatter(clause_probs_comp, batch, dim=0 , reduce=\"sum\") #expected_loss#*normalize\n",
    "            \n",
    "            num_clauses = (map(len, [i[0].clauses for i in data.formula]))\n",
    "            uniform_prob = torch.tensor([0.125*i for i in num_clauses]) #union bound for uniform probability\n",
    "\n",
    "            total_loss += [loss.mean()]\n",
    "            \n",
    "            iterations += 1\n",
    "\n",
    "            \n",
    "        exponents = torch.arange(self.num_iterations,device='cuda')\n",
    "        \n",
    "                ## NUM CLAUSES, C/V RATIO, LLL SAT RATIO \n",
    "        num_vars = torch.tensor([(data.x[data.batch==num]==0).sum().item() for num in data.batch.unique()], device='cuda')\n",
    "        num_clauses =  torch.tensor([(data.x[data.batch==num]==1).sum().item() for num in data.batch.unique()], device='cuda')\n",
    "        LLL_check =  clause_probs_comp\n",
    "        LLL_diff = clause_probs_comp[select_clauses]\n",
    "        LLL_loss = scatter(LLL_diff, batch[select_clauses], dim=0 , reduce=\"sum\") #shape: 32\n",
    "        UnionBoundCheck = (LLL_loss<=1.)*1.\n",
    "        \n",
    "        #breakpoint()\n",
    "        #### RATIOS/STATS\n",
    "        c_v_ratio = num_clauses/num_vars\n",
    "        clauses_satisfied = scatter(LLL_check*1., batch, dim=0 , reduce=\"sum\")        \n",
    "        perc_of_clauses_satisfied_per_graph = clauses_satisfied/num_clauses\n",
    "\n",
    "\n",
    "        retdict = {}\n",
    "        ub_term = LLL_loss\n",
    "        final_loss = ub_term # + LLL_gamma*LLL_prob\n",
    "        \n",
    "        #################################\n",
    "        #scatter plot\n",
    "        hardness_unionbound_scatterplot = torch.cat([c_v_ratio.unsqueeze(-1), loss.unsqueeze(-1)],dim=1)\n",
    "\n",
    "\n",
    "        #color\n",
    "        color = (c_v_ratio.unsqueeze(-1)).detach()\n",
    "        color = color/color.max().item()\n",
    "        color = torch.round(color*255.)\n",
    "        dummy = torch.zeros_like(color)\n",
    "        color_r = torch.cat([color ,dummy,dummy],dim=1)\n",
    "        color_g = torch.cat([dummy,color, dummy],dim=1)\n",
    "        \n",
    "\n",
    "        is_sat = torch.tensor([sat*1. for sat in data.sat],device='cuda').unsqueeze(-1)\n",
    "        final_color = is_sat * color_g  + (1-is_sat)*color_r\n",
    "\n",
    "        retdict[\"output\"] = [probs.squeeze(-1),\"hist\"]   #output\n",
    "        retdict[\"union bound avg\"] = [LLL_loss.mean().squeeze(),\"sequence\"] #final loss\n",
    "        retdict[\"loss\"] = [final_loss.mean().squeeze(),\"sequence\"] #final loss\n",
    "        retdict[\"union bound\"] = [loss.mean().squeeze(),\"sequence\"] #final loss\n",
    "        retdict[\"loss_comp\"] = [loss_comp.mean().squeeze(),\"null\"] #final loss\n",
    "        # retdict[\"percent LLL constraints satisfied\"] =  [true_perc_of_clauses_satisfied_per_graph,'hist']\n",
    "        # retdict[\"average percentage of LLL constraints satisfied\"] =  [true_perc_of_clauses_satisfied_per_graph.mean(),'sequence']\n",
    "        retdict[\"union bound/hardness (c/v ratio)\"] = [hardness_unionbound_scatterplot, 'scatter',final_color]\n",
    "        #retdict[\"LLL bound sat percentage/hardness (c/v ratio)\"] = [hardness_lllbound_scatterplot, 'scatter',final_color]\n",
    "        retdict[\"clause_probs\"] = [clause_probs_comp[data.x==1], \"hist\"]\n",
    "        retdict[\"clause_probs_full\"] = [clause_probs_comp, \"null\"]\n",
    "        retdict['variable probs'] = [var_probs.squeeze(),'hist']\n",
    "        retdict[\"variable_probs_full\"] = [probs,'null']\n",
    "        retdict[\"union bounds\"] = [LLL_loss.squeeze(),'hist']\n",
    "        retdict[\"union bound sat\"] = [UnionBoundCheck.squeeze(),'hist']\n",
    "\n",
    "        \n",
    "        return retdict\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "numlayers=2\n",
    "receptive_field= numlayers + 1\n",
    "val_losses = []\n",
    "cliq_dists = []\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lr_decay_step_size = 20\n",
    "lr_decay_factor = 0.95\n",
    "lr_lower_bound = 0.000001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ErdoSAT_repo: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir 'ErdoSAT_repo'\n",
    "#for validation checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current graph:  0\n",
      "current graph:  1\n",
      "current graph:  2\n",
      "current graph:  3\n",
      "current graph:  4\n",
      "current graph:  5\n",
      "current graph:  6\n",
      "current graph:  7\n",
      "current graph:  8\n",
      "current graph:  9\n",
      "current graph:  10\n",
      "current graph:  11\n",
      "current graph:  12\n",
      "current graph:  13\n",
      "current graph:  14\n",
      "current graph:  15\n",
      "current graph:  16\n",
      "current graph:  17\n",
      "current graph:  18\n",
      "current graph:  19\n",
      "current graph:  20\n",
      "current graph:  21\n",
      "current graph:  22\n",
      "current graph:  23\n",
      "current graph:  24\n",
      "current graph:  25\n",
      "current graph:  26\n",
      "current graph:  27\n",
      "current graph:  28\n",
      "current graph:  29\n",
      "current graph:  30\n",
      "current graph:  31\n",
      "current graph:  32\n",
      "current graph:  33\n",
      "current graph:  34\n",
      "current graph:  35\n",
      "current graph:  36\n",
      "current graph:  37\n",
      "current graph:  38\n",
      "current graph:  39\n",
      "current graph:  40\n",
      "current graph:  41\n",
      "current graph:  42\n",
      "current graph:  43\n",
      "current graph:  44\n",
      "current graph:  45\n",
      "current graph:  46\n",
      "current graph:  47\n",
      "current graph:  48\n",
      "current graph:  49\n",
      "current graph:  50\n",
      "current graph:  51\n",
      "current graph:  52\n",
      "current graph:  53\n",
      "current graph:  54\n",
      "current graph:  55\n",
      "current graph:  56\n",
      "current graph:  57\n",
      "current graph:  58\n",
      "current graph:  59\n",
      "current graph:  60\n",
      "current graph:  61\n",
      "current graph:  62\n",
      "current graph:  63\n",
      "current graph:  64\n",
      "current graph:  65\n",
      "current graph:  66\n",
      "current graph:  67\n",
      "current graph:  68\n",
      "current graph:  69\n",
      "current graph:  70\n",
      "current graph:  71\n",
      "current graph:  72\n",
      "current graph:  73\n",
      "current graph:  74\n",
      "current graph:  75\n",
      "current graph:  76\n",
      "current graph:  77\n",
      "current graph:  78\n",
      "current graph:  79\n",
      "current graph:  80\n",
      "current graph:  81\n",
      "current graph:  82\n",
      "current graph:  83\n",
      "current graph:  84\n",
      "current graph:  85\n",
      "current graph:  86\n",
      "current graph:  87\n",
      "current graph:  88\n",
      "current graph:  89\n",
      "current graph:  90\n",
      "current graph:  91\n",
      "current graph:  92\n",
      "current graph:  93\n",
      "current graph:  94\n",
      "current graph:  95\n",
      "current graph:  96\n",
      "current graph:  97\n",
      "current graph:  98\n",
      "current graph:  99\n",
      "current graph:  100\n",
      "current graph:  101\n",
      "current graph:  102\n",
      "current graph:  103\n",
      "current graph:  104\n",
      "current graph:  105\n",
      "current graph:  106\n",
      "current graph:  107\n",
      "current graph:  108\n",
      "current graph:  109\n",
      "current graph:  110\n",
      "current graph:  111\n",
      "current graph:  112\n",
      "current graph:  113\n",
      "current graph:  114\n",
      "current graph:  115\n",
      "current graph:  116\n",
      "current graph:  117\n",
      "current graph:  118\n",
      "current graph:  119\n",
      "current graph:  120\n",
      "current graph:  121\n",
      "current graph:  122\n",
      "current graph:  123\n",
      "current graph:  124\n",
      "current graph:  125\n",
      "current graph:  126\n",
      "current graph:  127\n",
      "current graph:  128\n",
      "current graph:  129\n",
      "current graph:  130\n",
      "current graph:  131\n",
      "current graph:  132\n",
      "current graph:  133\n",
      "current graph:  134\n",
      "current graph:  135\n",
      "current graph:  136\n",
      "current graph:  137\n",
      "current graph:  138\n",
      "current graph:  139\n",
      "current graph:  140\n",
      "current graph:  141\n",
      "current graph:  142\n",
      "current graph:  143\n",
      "current graph:  144\n",
      "current graph:  145\n",
      "current graph:  146\n",
      "current graph:  147\n",
      "current graph:  148\n",
      "current graph:  149\n",
      "current graph:  150\n",
      "current graph:  151\n",
      "current graph:  152\n",
      "current graph:  153\n",
      "current graph:  154\n",
      "current graph:  155\n",
      "current graph:  156\n",
      "current graph:  157\n",
      "current graph:  158\n",
      "current graph:  159\n",
      "current graph:  160\n",
      "current graph:  161\n",
      "current graph:  162\n",
      "current graph:  163\n",
      "current graph:  164\n",
      "current graph:  165\n",
      "current graph:  166\n",
      "current graph:  167\n",
      "current graph:  168\n",
      "current graph:  169\n",
      "current graph:  170\n",
      "current graph:  171\n",
      "current graph:  172\n",
      "current graph:  173\n",
      "current graph:  174\n",
      "current graph:  175\n",
      "current graph:  176\n",
      "current graph:  177\n",
      "current graph:  178\n",
      "current graph:  179\n",
      "current graph:  180\n",
      "current graph:  181\n",
      "current graph:  182\n",
      "current graph:  183\n",
      "current graph:  184\n",
      "current graph:  185\n",
      "current graph:  186\n",
      "current graph:  187\n",
      "current graph:  188\n",
      "current graph:  189\n",
      "current graph:  190\n",
      "current graph:  191\n",
      "current graph:  192\n",
      "current graph:  193\n",
      "current graph:  194\n",
      "current graph:  195\n",
      "current graph:  196\n",
      "current graph:  197\n",
      "current graph:  198\n",
      "current graph:  199\n",
      "current graph:  200\n",
      "current graph:  201\n",
      "current graph:  202\n",
      "current graph:  203\n",
      "current graph:  204\n",
      "current graph:  205\n",
      "current graph:  206\n",
      "current graph:  207\n",
      "current graph:  208\n",
      "current graph:  209\n",
      "current graph:  210\n",
      "current graph:  211\n",
      "current graph:  212\n",
      "current graph:  213\n",
      "current graph:  214\n",
      "current graph:  215\n",
      "current graph:  216\n",
      "current graph:  217\n",
      "current graph:  218\n",
      "current graph:  219\n",
      "current graph:  220\n",
      "current graph:  221\n",
      "current graph:  222\n",
      "current graph:  223\n",
      "current graph:  224\n",
      "current graph:  225\n",
      "current graph:  226\n",
      "current graph:  227\n",
      "current graph:  228\n",
      "current graph:  229\n",
      "current graph:  230\n",
      "current graph:  231\n",
      "current graph:  232\n",
      "current graph:  233\n",
      "current graph:  234\n",
      "current graph:  235\n",
      "current graph:  236\n",
      "current graph:  237\n",
      "current graph:  238\n",
      "current graph:  239\n",
      "current graph:  240\n",
      "current graph:  241\n",
      "current graph:  242\n",
      "current graph:  243\n",
      "current graph:  244\n",
      "current graph:  245\n",
      "current graph:  246\n",
      "current graph:  247\n",
      "current graph:  248\n",
      "current graph:  249\n",
      "current graph:  250\n",
      "current graph:  251\n",
      "current graph:  252\n",
      "current graph:  253\n",
      "current graph:  254\n",
      "current graph:  255\n",
      "current graph:  256\n",
      "current graph:  257\n",
      "current graph:  258\n",
      "current graph:  259\n",
      "current graph:  260\n",
      "current graph:  261\n",
      "current graph:  262\n",
      "current graph:  263\n",
      "current graph:  264\n",
      "current graph:  265\n",
      "current graph:  266\n",
      "current graph:  267\n",
      "current graph:  268\n",
      "current graph:  269\n",
      "current graph:  270\n",
      "current graph:  271\n",
      "current graph:  272\n",
      "current graph:  273\n",
      "current graph:  274\n",
      "current graph:  275\n",
      "current graph:  276\n",
      "current graph:  277\n",
      "current graph:  278\n",
      "current graph:  279\n",
      "current graph:  280\n",
      "current graph:  281\n",
      "current graph:  282\n",
      "current graph:  283\n",
      "current graph:  284\n",
      "current graph:  285\n",
      "current graph:  286\n",
      "current graph:  287\n",
      "current graph:  288\n",
      "current graph:  289\n",
      "current graph:  290\n",
      "current graph:  291\n",
      "current graph:  292\n",
      "current graph:  293\n",
      "current graph:  294\n",
      "current graph:  295\n",
      "current graph:  296\n",
      "current graph:  297\n",
      "current graph:  298\n",
      "current graph:  299\n"
     ]
    }
   ],
   "source": [
    "##validation set\n",
    "big_large_easy_validation = generate_RandomCNFDataset(300,3,100,400,num_variables_high=101, num_clauses_high=401);\n",
    "infinite_data = True\n",
    "if not infinite_data:\n",
    "    big_large_easy_train = generate_RandomCNFDataset(1500,3,100,400,num_variables_high=101, num_clauses_high=401);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Validation Loss:  tensor(48.7628, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  0\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(51.6538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(51.7489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(41.3410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  3\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(34.9698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  4\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(32.5904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  5\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(31.2321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  6\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(30.4038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  7\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(29.6858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  8\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(29.4544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  9\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(28.9024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  10\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(28.8590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  11\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(28.6615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  12\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(28.1141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  13\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(27.8977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  14\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(27.6876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  15\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(26.4465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  16\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(25.8923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  17\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(25.4772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  18\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(24.2862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  19\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(23.1267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(22.6146, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  20\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(22.0654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  21\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(21.2378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  22\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(20.7012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  23\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(19.8681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  24\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(19.4985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  25\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(18.1295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  26\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(17.6586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  27\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(17.6520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  28\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(17.2012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  29\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(16.8538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  30\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(16.0462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  31\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(16.0670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  32\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(17.6210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  33\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(16.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  34\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(15.9129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  35\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(15.2664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  36\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(15.1733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  37\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(14.7371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  38\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(14.5804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  39\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(16.1811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(14.8417, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  40\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(15.2913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  41\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(14.8917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  42\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(15.1428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  43\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(14.0374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  44\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(14.1629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  45\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(13.5318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  46\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(13.0145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  47\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(13.2943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  48\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(13.7648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  49\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(13.3882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  50\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(12.8459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  51\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(13.2543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  52\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(13.2999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  53\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(14.0818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  54\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(13.5136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  55\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.8168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  56\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.8267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  57\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.6556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  58\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.7701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  59\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.9127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(10.8341, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  60\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.6796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  61\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.6506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  62\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(12.1263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  63\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(12.1368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  64\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.4116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  65\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(12.6011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  66\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(12.7657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  67\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(12.1365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  68\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.2307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  69\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.8458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  70\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.5643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  71\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.9325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  72\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.8476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  73\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.9334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  74\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(12.1890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  75\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(12.3794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  76\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.5630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  77\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.4012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  78\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.7841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  79\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.7368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(11.0141, device='cuda:0')\n",
      "Epoch:  80\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.5858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  81\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.5799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  82\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.6144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  83\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.3587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  84\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.2829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  85\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.4746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  86\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.3228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  87\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.2661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  88\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.4053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  89\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.1557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  90\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.7832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  91\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.9569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  92\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.2815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  93\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.9799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  94\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.1080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  95\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.6307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  96\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.6555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  97\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.9964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  98\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(12.5272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  99\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.1507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(12.1647, device='cuda:0')\n",
      "Epoch:  100\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.6223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  101\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.6403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  102\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.2058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  103\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.6739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  104\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.1769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  105\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.1513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  106\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.0576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  107\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.8191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  108\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.4413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  109\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.1659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  110\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(12.0544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  111\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(12.0731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  112\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.1853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  113\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.4878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  114\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.8758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  115\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.4185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  116\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.2871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  117\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.4384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  118\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.6425, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  119\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.0575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(10.7268, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  120\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.2128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  121\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.1141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  122\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.6338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  123\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.1258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  124\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.5755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  125\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.1338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  126\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.3954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  127\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.1732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  128\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.4027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  129\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.4569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  130\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.6859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  131\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.3029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  132\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.9998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  133\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.4478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  134\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.8446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  135\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.5165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  136\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.8185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  137\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.6443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  138\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.5745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  139\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.7165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(9.0829, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  140\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.1544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  141\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.4020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  142\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  143\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.8819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  144\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.1701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  145\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.8865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  146\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.9288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  147\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.9240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  148\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.5449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  149\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.7050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  150\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.2053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  151\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.3824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  152\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  153\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.4654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  154\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.6143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  155\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.4317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  156\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.1837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  157\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.2133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  158\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.9229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  159\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.9065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(9.9277, device='cuda:0')\n",
      "Epoch:  160\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.0618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  161\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.8037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  162\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.6954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  163\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(12.1989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  164\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(12.8512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  165\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.9027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  166\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.3835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  167\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.1771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  168\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.1448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  169\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.8297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  170\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.9368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  171\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.9239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  172\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.9323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  173\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.2488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  174\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(12.6069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  175\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.1718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  176\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.3528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  177\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.7222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  178\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.8519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  179\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.8787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(11.8817, device='cuda:0')\n",
      "Epoch:  180\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(11.7006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  181\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.5885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  182\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.7421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  183\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.9466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  184\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.8631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  185\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.2198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  186\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.1576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  187\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.1697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  188\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.1300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  189\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  190\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  191\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.6468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  192\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.2245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  193\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.8859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  194\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.0939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  195\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.7516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  196\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.7914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  197\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.9656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  198\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.8480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  199\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.1931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(9.2250, device='cuda:0')\n",
      "Epoch:  200\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.4074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  201\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.9763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  202\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.7868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  203\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.8413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  204\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.1868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  205\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.1170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  206\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.8861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  207\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.1209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  208\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.6885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  209\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.3119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  210\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.8624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  211\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.0145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  212\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  213\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.2679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  214\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.5463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  215\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  216\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  217\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  218\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.8409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  219\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(9.1024, device='cuda:0')\n",
      "Epoch:  220\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.7802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  221\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  222\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.9345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  223\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.9181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  224\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.7532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  225\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.9955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  226\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  227\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.4406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  228\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.2774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  229\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.1467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  230\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.6206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  231\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.4610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  232\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  233\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  234\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  235\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  236\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  237\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  238\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  239\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(8.4278, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  240\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  241\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  242\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.6337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  243\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.7308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  244\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.4303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  245\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.7938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  246\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.4337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  247\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.4806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  248\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.5725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  249\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.4196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  250\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  251\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  252\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.1122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  253\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.3353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  254\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  255\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  256\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.9956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  257\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  258\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  259\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(8.4020, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  260\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  261\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.4772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  262\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.6233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  263\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.8378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  264\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.5027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  265\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.2775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  266\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.8814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  267\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.2627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  268\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  269\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.8166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  270\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.6216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  271\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.7175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  272\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  273\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.9811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  274\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  275\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.9736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  276\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.3701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  277\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.9028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  278\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.9426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  279\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(8.8125, device='cuda:0')\n",
      "Epoch:  280\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  281\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5601, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  282\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  283\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  284\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  285\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.9660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  286\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.8543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  287\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.7494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  288\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.8492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  289\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.0119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  290\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.6167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  291\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.8631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  292\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.8039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  293\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.2688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  294\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  295\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.4028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  296\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  297\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.1776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  298\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.8598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  299\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.6538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(9.0886, device='cuda:0')\n",
      "Epoch:  300\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.8013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  301\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.7669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  302\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  303\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.5362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  304\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.4914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  305\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.9666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  306\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.6720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  307\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  308\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  309\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.4621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  310\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.8562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  311\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  312\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.2309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  313\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.9853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  314\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.2217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  315\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.7964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  316\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.9129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  317\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.7064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  318\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  319\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.8445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(9.8067, device='cuda:0')\n",
      "Epoch:  320\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.1538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  321\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.3947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  322\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.2342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  323\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.0720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  324\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.2864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  325\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  326\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.3925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  327\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.6214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  328\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  329\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.2645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  330\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.8640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  331\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  332\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  333\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  334\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  335\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.4038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  336\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.8196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  337\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  338\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  339\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.4404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(10.2159, device='cuda:0')\n",
      "Epoch:  340\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.8879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  341\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.6822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  342\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.6966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  343\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  344\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  345\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  346\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  347\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  348\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.4447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  349\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  350\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  351\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  352\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  353\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  354\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.6967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  355\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  356\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.7361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  357\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  358\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  359\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(8.1989, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  360\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.7713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  361\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  362\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  363\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.4988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  364\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  365\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  366\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.4483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  367\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  368\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.9483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  369\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  370\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.4203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  371\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  372\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  373\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.4144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  374\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  375\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.7106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  376\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  377\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  378\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  379\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(8.5027, device='cuda:0')\n",
      "Epoch:  380\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  381\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  382\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.1646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  383\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.9428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  384\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.9968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  385\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.6580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  386\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  387\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  388\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  389\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  390\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.8254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  391\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  392\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  393\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  394\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.2531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  395\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  396\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  397\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  398\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  399\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(8.7268, device='cuda:0')\n",
      "Epoch:  400\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.6955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  401\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  402\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  403\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  404\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  405\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.9087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  406\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.4558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  407\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.9302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  408\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.9084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  409\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  410\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  411\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  412\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  413\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  414\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.4788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  415\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.4333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  416\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  417\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  418\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  419\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(8.4788, device='cuda:0')\n",
      "Epoch:  420\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.4344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  421\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  422\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  423\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  424\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  425\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.6044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  426\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.8684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  427\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  428\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.6424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  429\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  430\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.8993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  431\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  432\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  433\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  434\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  435\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.8602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  436\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.8216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  437\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  438\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0632, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  439\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0425, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(7.8778, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  440\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.7241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  441\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.8413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  442\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.5322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  443\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  444\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.6852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  445\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.1923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  446\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.3134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  447\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.9515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  448\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  449\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.6513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  450\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  451\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  452\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  453\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.4331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  454\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  455\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.8762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  456\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.4265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  457\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  458\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  459\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(8.4875, device='cuda:0')\n",
      "Epoch:  460\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  461\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  462\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  463\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.0334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  464\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.6654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  465\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.5721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  466\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.7473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  467\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  468\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  469\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  470\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  471\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  472\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  473\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  474\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  475\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.8917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  476\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  477\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  478\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  479\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.8479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(7.9015, device='cuda:0')\n",
      "Epoch:  480\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.7436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  481\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.7006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  482\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.6956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  483\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.6157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  484\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.8066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  485\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  486\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.6071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  487\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.6059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  488\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  489\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  490\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  491\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.6899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  492\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  493\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.5948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  494\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  495\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.5782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  496\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  497\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  498\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.5873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  499\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(8.0690, device='cuda:0')\n",
      "Epoch:  500\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  501\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.1720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  502\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  503\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  504\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.6561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  505\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.6593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  506\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  507\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  508\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.7751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  509\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  510\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  511\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.3690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  512\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.5020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  513\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.5873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  514\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  515\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  516\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.5518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  517\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  518\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  519\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(7.7251, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  520\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  521\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  522\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  523\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.6961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  524\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  525\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.8536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  526\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(10.0242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  527\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(9.1355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  528\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.8055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  529\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  530\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  531\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.6557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  532\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  533\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.2821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  534\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.7540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  535\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  536\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  537\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  538\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  539\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.5421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(8.0438, device='cuda:0')\n",
      "Epoch:  540\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  541\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.8550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  542\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  543\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.7543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  544\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  545\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.8709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  546\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  547\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.3776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  548\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  549\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.5306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  550\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.3452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  551\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.5953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  552\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(8.0936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  553\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  554\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.8193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  555\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.7786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  556\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.5854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  557\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.3278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  558\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.7123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  559\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(7.5876, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  560\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  561\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.6000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  562\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  563\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  564\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  565\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  566\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  567\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  568\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  569\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.3931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  570\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  571\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  572\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.3335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  573\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.3210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  574\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  575\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.7759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  576\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.5930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  577\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  578\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  579\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.3363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(7.1992, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  580\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  581\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  582\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  583\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  584\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  585\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  586\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  587\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  588\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  589\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  590\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  591\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  592\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  593\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  594\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  595\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  596\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.3491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  597\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.5974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  598\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.5149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  599\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.3739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(7.4233, device='cuda:0')\n",
      "Epoch:  600\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  601\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.6676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  602\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.3417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  603\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  604\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.3972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  605\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  606\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  607\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  608\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  609\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  610\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  611\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  612\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  613\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  614\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.5298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  615\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  616\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  617\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  618\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  619\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(7.0451, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  620\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  621\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  622\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  623\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  624\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  625\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  626\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  627\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  628\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  629\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  630\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  631\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  632\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  633\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  634\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  635\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  636\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  637\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  638\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  639\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(7.0835, device='cuda:0')\n",
      "Epoch:  640\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  641\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  642\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  643\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0315, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  644\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  645\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  646\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  647\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  648\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  649\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  650\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  651\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  652\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  653\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  654\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  655\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  656\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  657\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  658\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  659\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(7.2609, device='cuda:0')\n",
      "Epoch:  660\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  661\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  662\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  663\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  664\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  665\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  666\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  667\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  668\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  669\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  670\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  671\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  672\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  673\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  674\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  675\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  676\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  677\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  678\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  679\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.9403, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  680\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  681\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  682\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.3480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  683\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.5870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  684\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  685\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  686\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  687\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  688\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  689\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  690\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  691\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  692\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  693\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  694\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  695\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  696\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  697\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  698\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  699\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.9193, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  700\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  701\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  702\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  703\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  704\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  705\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  706\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  707\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  708\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  709\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  710\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  711\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  712\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  713\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  714\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  715\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  716\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  717\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  718\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  719\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.7256, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  720\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  721\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  722\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  723\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  724\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  725\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.3832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  726\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  727\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  728\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  729\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  730\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  731\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  732\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  733\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  734\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  735\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  736\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  737\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  738\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  739\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(7.3228, device='cuda:0')\n",
      "Epoch:  740\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  741\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.6536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  742\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  743\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.3752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  744\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.3288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  745\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  746\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.6782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  747\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.5193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  748\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.3651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  749\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.4018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  750\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  751\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  752\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  753\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  754\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  755\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  756\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  757\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  758\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  759\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.7988, device='cuda:0')\n",
      "Epoch:  760\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  761\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  762\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  763\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  764\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  765\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  766\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  767\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  768\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  769\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  770\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  771\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  772\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  773\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  774\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  775\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  776\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  777\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  778\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  779\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.8673, device='cuda:0')\n",
      "Epoch:  780\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  781\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  782\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  783\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  784\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  785\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  786\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  787\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  788\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  789\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  790\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  791\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  792\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  793\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  794\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  795\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  796\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.2624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  797\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  798\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  799\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(7.0940, device='cuda:0')\n",
      "Epoch:  800\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  801\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  802\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  803\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  804\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  805\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  806\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  807\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  808\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6294, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  809\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  810\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  811\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  812\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  813\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  814\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  815\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  816\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  817\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  818\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  819\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.5908, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  820\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  821\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  822\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  823\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  824\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4634, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  825\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  826\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  827\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  828\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  829\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  830\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  831\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  832\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  833\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  834\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  835\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  836\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  837\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  838\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  839\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.7068, device='cuda:0')\n",
      "Epoch:  840\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  841\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  842\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  843\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  844\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  845\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.0588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  846\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  847\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  848\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  849\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  850\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  851\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  852\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  853\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  854\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  855\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  856\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  857\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  858\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  859\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.5420, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  860\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  861\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  862\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  863\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  864\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  865\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  866\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  867\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  868\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  869\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  870\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  871\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  872\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  873\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  874\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  875\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  876\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  877\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  878\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  879\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.4252, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  880\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  881\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  882\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  883\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  884\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  885\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  886\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  887\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  888\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  889\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  890\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  891\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  892\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  893\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  894\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  895\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  896\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  897\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  898\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  899\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.3947, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  900\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  901\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  902\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  903\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  904\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  905\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  906\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  907\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  908\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  909\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  910\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  911\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(7.1704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  912\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  913\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  914\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  915\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  916\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  917\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  918\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  919\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.4207, device='cuda:0')\n",
      "Epoch:  920\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  921\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.9311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  922\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  923\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  924\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  925\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  926\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  927\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  928\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  929\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  930\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  931\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  932\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  933\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  934\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  935\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  936\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  937\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  938\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  939\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.3127, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  940\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  941\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  942\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  943\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  944\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  945\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  946\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  947\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  948\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  949\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  950\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.8553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  951\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  952\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  953\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  954\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  955\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2068, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  956\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  957\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  958\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  959\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.4925, device='cuda:0')\n",
      "Epoch:  960\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  961\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  962\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  963\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  964\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  965\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  966\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  967\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  968\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  969\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  970\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  971\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  972\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  973\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  974\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  975\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  976\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  977\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  978\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  979\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.2800, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  980\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  981\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  982\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  983\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  984\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  985\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  986\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  987\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  988\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  989\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  990\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  991\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  992\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  993\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  994\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  995\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  996\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  997\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  998\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  999\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.1894, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  1000\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1001\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1002\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1003\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1004\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1005\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1006\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1007\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1008\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1009\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1010\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1011\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1012\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1013\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1014\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1015\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1016\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1017\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1018\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1019\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.0980, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  1020\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1021\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1022\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1023\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1024\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1025\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1026\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1027\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1028\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1029\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1030\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.7799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1031\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1032\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1033\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1034\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1035\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1036\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1037\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1038\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1039\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.3854, device='cuda:0')\n",
      "Epoch:  1040\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1041\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1042\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1043\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1044\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1045\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1046\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1047\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1048\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1049\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1050\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1051\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1052\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1053\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1054\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1055\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1056\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1057\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1058\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1059\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.1508, device='cuda:0')\n",
      "Epoch:  1060\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1061\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1062\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1063\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1064\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1065\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1066\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1067\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1068\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1069\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1070\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1071\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1072\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1073\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1074\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1075\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1076\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1077\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1078\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1079\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.0744, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  1080\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1081\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1082\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1083\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1084\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1085\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1086\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1087\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1088\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1089\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1090\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1091\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1092\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1093\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1094\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1095\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1096\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1097\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1098\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1099\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.2136, device='cuda:0')\n",
      "Epoch:  1100\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1101\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1102\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.6916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1103\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1104\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1105\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1106\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1107\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1108\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1109\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1110\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1111\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1112\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1113\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1114\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1115\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1116\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1117\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1118\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1119\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.1531, device='cuda:0')\n",
      "Epoch:  1120\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1121\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1122\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1123\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1124\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1125\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1126\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1127\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1128\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1129\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1130\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1131\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1132\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1133\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1134\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1135\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1136\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1137\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1138\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1139\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.1499, device='cuda:0')\n",
      "Epoch:  1140\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2231, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1141\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1142\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1143\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1144\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1145\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1146\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1147\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1148\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1149\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1150\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1151\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1152\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1153\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1154\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1155\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1156\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1157\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1158\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1159\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.1081, device='cuda:0')\n",
      "Epoch:  1160\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1161\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1162\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1163\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1164\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1165\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1166\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1167\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1168\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1169\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1170\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1171\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1172\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1173\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1174\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1175\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1176\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1177\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1178\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1179\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.1467, device='cuda:0')\n",
      "Epoch:  1180\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1181\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1182\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1183\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1184\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1185\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1186\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1187\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1188\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1189\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1190\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1191\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1192\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1193\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1194\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1195\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1196\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.5008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1197\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1198\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1199\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.1680, device='cuda:0')\n",
      "Epoch:  1200\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1201\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1202\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1203\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1204\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1205\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1206\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1207\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1208\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1209\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1210\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1211\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1212\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1213\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1214\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1215\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1216\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1217\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1218\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1219\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.0895, device='cuda:0')\n",
      "Epoch:  1220\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1221\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1222\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1223\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1224\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1225\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1226\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1227\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1228\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1229\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1230\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1231\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1232\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1233\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1234\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1235\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1236\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1237\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1238\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1239\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.9831, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  1240\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1241\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1242\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1243\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1244\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1245\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1246\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1247\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1248\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1249\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1250\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1251\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1252\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1253\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1254\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1255\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1256\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1257\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1258\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1259\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.0190, device='cuda:0')\n",
      "Epoch:  1260\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1261\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1262\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1263\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1264\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1265\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1266\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1267\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1268\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1269\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1270\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9634, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1271\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1272\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1273\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1274\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1275\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1276\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1277\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1278\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1279\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.0518, device='cuda:0')\n",
      "Epoch:  1280\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1281\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1282\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1283\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1284\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1285\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1286\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1287\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1288\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1289\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1290\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1291\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1292\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1293\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1294\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1295\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1296\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1297\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1298\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1299\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.1154, device='cuda:0')\n",
      "Epoch:  1300\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1301\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1302\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1303\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1304\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1305\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1306\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1307\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1308\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1309\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1310\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1311\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1312\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1313\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1314\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1315\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1316\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1317\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1318\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1319\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.1017, device='cuda:0')\n",
      "Epoch:  1320\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1321\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1322\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1323\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1324\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1325\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1326\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1327\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1328\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1329\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1330\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1331\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1332\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1333\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1334\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1335\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1336\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1337\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1338\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1339\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(6.1347, device='cuda:0')\n",
      "Epoch:  1340\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1341\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1342\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1343\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1344\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1345\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1346\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8634, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1347\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1348\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1349\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1350\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1351\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1352\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1353\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1354\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1355\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1356\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1357\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1358\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1359\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.9722, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  1360\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1361\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1362\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1363\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1364\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1365\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1366\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1367\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1368\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1369\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1370\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1371\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1372\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8313, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1373\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1374\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1375\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1376\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1377\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1378\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1379\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.9891, device='cuda:0')\n",
      "Epoch:  1380\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1381\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1382\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1383\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1384\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1385\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1386\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1387\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1388\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1389\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1390\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1391\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1392\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1393\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1394\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1395\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1396\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1397\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1398\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1399\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.9893, device='cuda:0')\n",
      "Epoch:  1400\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1401\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1402\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.4007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1403\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1404\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1405\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1406\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1407\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1408\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1409\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1410\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1411\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1412\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1413\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1414\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1415\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1416\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1417\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1418\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1419\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.9229, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  1420\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1421\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1422\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1423\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1424\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1425\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1426\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1427\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1428\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1429\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1430\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1431\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1432\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1433\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1434\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1435\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1436\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1437\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1438\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1439\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.8515, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  1440\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1441\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1442\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1443\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1444\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1445\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1446\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1447\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1448\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1449\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1450\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1451\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1452\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1453\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1454\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1455\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1456\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1457\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1458\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1459\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.8962, device='cuda:0')\n",
      "Epoch:  1460\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1461\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1462\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1463\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1464\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1465\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1466\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1467\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1468\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1469\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1470\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1471\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1472\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1473\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1474\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1475\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1476\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1477\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1478\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1479\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.9312, device='cuda:0')\n",
      "Epoch:  1480\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1481\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1482\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1483\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1484\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1485\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1486\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1487\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1488\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1489\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1490\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1491\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1492\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1493\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1494\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1495\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1496\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1497\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1498\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1499\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.8831, device='cuda:0')\n",
      "Epoch:  1500\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1501\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1502\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1503\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1504\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1505\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1506\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1507\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1508\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1509\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1510\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1511\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1512\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1513\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1514\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1515\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1516\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1517\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1518\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1519\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.8752, device='cuda:0')\n",
      "Epoch:  1520\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1521\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1522\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1523\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1524\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1525\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1526\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1527\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1528\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1529\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1530\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1531\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1532\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1533\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1534\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1535\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1536\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1537\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1538\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1539\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.8261, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  1540\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1541\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1542\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1543\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1544\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1545\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1546\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1547\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1548\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1549\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1550\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1551\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1552\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1553\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1554\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9634, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1555\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1556\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1557\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1558\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1559\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.8461, device='cuda:0')\n",
      "Epoch:  1560\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1561\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1562\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1563\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1564\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1565\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1566\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1567\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1568\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1569\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1570\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1571\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1572\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1573\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1574\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1575\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1576\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1577\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1578\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1579\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.8779, device='cuda:0')\n",
      "Epoch:  1580\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1581\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1582\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1583\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1584\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1585\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1586\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1587\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1588\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1589\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1590\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1591\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1592\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1593\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1594\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1595\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1596\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1597\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1598\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1599\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.8623, device='cuda:0')\n",
      "Epoch:  1600\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1601\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1602\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1603\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1604\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1605\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1606\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1607\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1608\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1609\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1610\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1611\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1612\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1613\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1614\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1615\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1616\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1617\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1618\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1619\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.8585, device='cuda:0')\n",
      "Epoch:  1620\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1621\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1622\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1623\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1624\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1625\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1626\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1627\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1628\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1629\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1630\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1631\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1632\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1633\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1634\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1635\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1636\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1637\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1638\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1639\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.8584, device='cuda:0')\n",
      "Epoch:  1640\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1641\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1642\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1643\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1644\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1645\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1646\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1647\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1648\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1649\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1650\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1651\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1652\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1653\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0231, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1654\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1655\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1656\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1657\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1658\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8634, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1659\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.8118, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  1660\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1661\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1662\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.3618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1663\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1664\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1665\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1666\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1667\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1668\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1669\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1670\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1671\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1672\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1673\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1674\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1675\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1676\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1677\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1678\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1679\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.8003, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  1680\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1681\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1682\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1683\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1684\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1685\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1686\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1687\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1688\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1689\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1690\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1691\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1692\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1693\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1694\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1695\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1696\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1697\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1698\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1699\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7782, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  1700\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1701\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1702\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1703\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1704\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1705\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1706\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1707\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.3726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1708\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1709\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1710\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1711\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1712\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1713\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1714\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1715\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1716\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1717\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1718\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1719\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7722, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  1720\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1721\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1722\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1723\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1724\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1725\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1726\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1727\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1728\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1729\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1730\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1731\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1732\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1733\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1734\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1735\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1736\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1737\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1738\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1739\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.8088, device='cuda:0')\n",
      "Epoch:  1740\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1741\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1742\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1743\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1744\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1745\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1746\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1747\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1748\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1749\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1750\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1751\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1752\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1753\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1754\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1755\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1756\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1757\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1758\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1759\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7887, device='cuda:0')\n",
      "Epoch:  1760\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1761\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1762\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1763\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1764\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1765\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1766\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1767\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1768\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1769\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1770\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1771\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1772\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1773\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1774\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1775\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1776\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1777\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1778\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1779\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7592, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  1780\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1781\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1782\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1783\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1784\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1785\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1786\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1787\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1788\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1789\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1790\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1791\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1792\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1793\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1794\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1795\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1796\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5092, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1797\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1798\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1799\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7651, device='cuda:0')\n",
      "Epoch:  1800\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1801\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1802\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1803\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1804\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1805\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1806\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1807\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1808\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1809\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1810\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1811\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1812\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1813\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1814\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1815\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1816\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1817\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1818\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1819\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7682, device='cuda:0')\n",
      "Epoch:  1820\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1821\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1822\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1823\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1824\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1825\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1826\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1827\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1828\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1829\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1830\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1831\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1832\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1833\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1834\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1835\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1836\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.2473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1837\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1838\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1839\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7960, device='cuda:0')\n",
      "Epoch:  1840\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1841\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1842\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1843\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1844\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1845\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1846\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1847\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1848\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1849\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1850\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1851\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1852\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1853\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1854\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1855\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1856\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1857\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1858\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1859\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7758, device='cuda:0')\n",
      "Epoch:  1860\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1861\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1862\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1863\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1864\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1865\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.3739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1866\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1867\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1868\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1869\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1870\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1871\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1872\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1873\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1874\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1875\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1876\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1877\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1878\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1879\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7762, device='cuda:0')\n",
      "Epoch:  1880\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1881\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1882\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1883\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1884\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1885\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1886\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.3817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1887\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1888\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1889\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1890\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1891\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1892\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1893\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1894\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1895\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1896\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1897\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1898\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1899\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7770, device='cuda:0')\n",
      "Epoch:  1900\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1901\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1902\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1903\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1904\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1905\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1906\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1907\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1908\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1909\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1910\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1911\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1912\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1913\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1914\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.2268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1915\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1916\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1917\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1918\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1919\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7564, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  1920\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1921\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1922\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1923\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1924\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1925\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1926\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1927\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1928\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1231, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1929\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1930\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1931\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1932\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1933\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1934\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1935\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1936\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1937\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1938\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1939\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7558, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  1940\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1941\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1942\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1943\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1944\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1945\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1946\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1947\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1948\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1949\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1950\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1951\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1952\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1953\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1954\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1955\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1956\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1957\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1958\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1959\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7595, device='cuda:0')\n",
      "Epoch:  1960\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1961\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1962\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1963\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1964\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1965\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1966\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1967\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1968\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1969\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1970\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1971\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1972\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1973\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1974\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1975\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1976\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1977\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1978\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1979\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7497, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  1980\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1981\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1982\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1983\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1984\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1985\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1986\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1987\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1988\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1989\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1990\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1991\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1992\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1993\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1994\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1995\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1996\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1997\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1998\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  1999\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7418, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  2000\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2001\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2002\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2003\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2004\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2005\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2006\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2007\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2008\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2009\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2010\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2011\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2012\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2013\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2014\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2015\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2016\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2017\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2018\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2019\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7557, device='cuda:0')\n",
      "Epoch:  2020\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2021\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2022\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2023\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2024\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2025\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2026\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2027\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2028\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2029\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2030\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2031\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2032\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2033\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2034\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2035\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2036\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2037\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2038\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2039\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7617, device='cuda:0')\n",
      "Epoch:  2040\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2041\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6276, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2042\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2043\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2044\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2045\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2046\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2047\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2048\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2049\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2050\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2051\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2052\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2053\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.3293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2054\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2055\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2056\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2057\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2058\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2059\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7414, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  2060\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2061\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2062\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2063\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2064\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2065\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2066\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2067\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2068\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2069\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2070\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2071\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.3889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2072\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2073\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2074\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2075\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2076\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2077\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2078\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2079\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7485, device='cuda:0')\n",
      "Epoch:  2080\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2081\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2082\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2083\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2084\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2085\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2086\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2087\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2088\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2089\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.2376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2090\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2091\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2092\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2093\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2094\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2095\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2096\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2097\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2098\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2099\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7482, device='cuda:0')\n",
      "Epoch:  2100\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2101\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2102\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2103\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2104\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2105\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2106\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2107\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2108\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2109\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2110\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2111\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2112\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2113\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2114\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2115\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2116\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2117\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2118\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2119\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7388, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  2120\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2121\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2122\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2123\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2124\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2125\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2126\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2127\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2128\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2129\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2130\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2131\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2132\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2133\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2134\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2135\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2136\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2137\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2138\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2139\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7262, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  2140\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2141\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2142\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2143\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2144\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2145\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2146\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2147\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2148\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2149\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2150\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2151\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2152\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2153\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2154\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2155\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2156\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2157\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2158\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.3978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2159\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7412, device='cuda:0')\n",
      "Epoch:  2160\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2161\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2162\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2163\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2164\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2165\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2166\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2167\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2168\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2169\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2170\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2171\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2172\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2173\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2174\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2175\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2176\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2177\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2178\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2179\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7280, device='cuda:0')\n",
      "Epoch:  2180\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2181\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2182\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2183\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2184\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2185\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2186\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2187\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2188\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2189\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2190\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2191\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2192\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2193\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2194\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2195\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2196\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2197\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2198\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.2172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2199\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7287, device='cuda:0')\n",
      "Epoch:  2200\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2201\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2202\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2203\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2204\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2205\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2206\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2207\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2208\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2209\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2210\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2211\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.3865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2212\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2213\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2214\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2215\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2216\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2217\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2218\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2219\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7247, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  2220\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2221\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2222\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2223\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2224\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2225\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2226\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2227\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2228\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2229\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6313, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2230\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2231\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2232\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2233\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2234\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2235\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2236\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2237\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2238\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2239\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7417, device='cuda:0')\n",
      "Epoch:  2240\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2241\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2242\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2243\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2244\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2245\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2246\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2247\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2248\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2249\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2250\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2251\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2252\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2253\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2254\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2255\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2256\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2257\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2258\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2259\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7340, device='cuda:0')\n",
      "Epoch:  2260\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2261\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2262\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2263\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2264\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2265\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2266\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2267\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2268\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2269\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2270\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2271\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2272\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2273\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2274\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2275\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2276\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2277\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2278\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2279\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7312, device='cuda:0')\n",
      "Epoch:  2280\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2281\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2282\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2283\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2284\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2285\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2286\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2287\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2288\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2289\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2290\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2291\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2292\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2293\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2294\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2295\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2296\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2297\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2298\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2299\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7429, device='cuda:0')\n",
      "Epoch:  2300\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2301\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2302\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2303\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2304\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2305\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2306\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2307\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2308\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2309\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2310\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2311\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2312\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2313\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2314\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2315\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2316\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.2567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2317\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2318\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2319\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7149, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  2320\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2321\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2322\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2323\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2324\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2325\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2326\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2327\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2328\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2329\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2330\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2331\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2332\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2333\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2334\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6370, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2335\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2336\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2337\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2338\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2339\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7125, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  2340\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2341\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2342\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2343\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2344\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2345\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2346\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2347\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2348\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2349\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2350\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2351\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2352\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2353\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2354\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2355\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2356\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2357\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2358\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2359\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7324, device='cuda:0')\n",
      "Epoch:  2360\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2361\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2362\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2363\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2364\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2365\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2366\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2367\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2368\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2369\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2370\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2371\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2372\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2373\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2374\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.2390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2375\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2376\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2377\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2378\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2379\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7242, device='cuda:0')\n",
      "Epoch:  2380\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2381\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2382\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2383\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2384\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2385\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2386\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2387\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2388\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2389\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2390\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2391\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2392\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2393\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2394\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2395\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2396\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2397\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2398\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2399\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7253, device='cuda:0')\n",
      "Epoch:  2400\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2401\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2402\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2403\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2404\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2405\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2406\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2407\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2408\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2409\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2410\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2411\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2412\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2413\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2414\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2415\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2416\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2417\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2418\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2419\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7202, device='cuda:0')\n",
      "Epoch:  2420\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2421\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2422\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2423\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2424\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2425\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2426\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2427\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2428\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2429\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2430\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2431\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2432\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2433\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2434\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2435\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2436\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2437\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2438\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2439\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7130, device='cuda:0')\n",
      "Epoch:  2440\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2441\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2442\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2443\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2444\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2445\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2446\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2447\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2448\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2449\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2450\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2451\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2452\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2453\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2454\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2455\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.3252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2456\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2457\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2458\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2459\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7055, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  2460\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2461\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2462\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2463\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2464\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2465\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2466\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2467\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2468\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2469\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2470\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2471\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2472\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2473\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2474\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2475\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2476\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2477\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2478\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2479\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.6951, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  2480\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2481\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2482\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2483\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2484\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2485\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2486\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2487\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2488\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2489\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2490\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2491\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2492\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2493\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2494\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2495\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2496\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2497\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2498\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2499\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.6892, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  2500\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2501\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2502\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2503\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2504\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2505\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2506\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2507\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2508\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2509\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2510\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2511\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2512\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2513\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9632, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2514\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2515\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2516\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2517\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2518\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2519\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7045, device='cuda:0')\n",
      "Epoch:  2520\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2521\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2522\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2523\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2524\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2525\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6315, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2526\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2527\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.3195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2528\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2529\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.3834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2530\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2531\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2532\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2533\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2534\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2535\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2536\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2537\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2538\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2539\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.6941, device='cuda:0')\n",
      "Epoch:  2540\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.3057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2541\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2542\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2543\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2544\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2545\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2546\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2547\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2548\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2549\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2550\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2551\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2552\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2553\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2554\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2555\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2556\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2557\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2558\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2559\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.6994, device='cuda:0')\n",
      "Epoch:  2560\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2561\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2562\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2563\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2564\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2565\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2566\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2567\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2568\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.3306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2569\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2570\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2571\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2572\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2573\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2574\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2575\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2576\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2577\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2578\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2579\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.6902, device='cuda:0')\n",
      "Epoch:  2580\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2581\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2582\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2583\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2584\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2585\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2586\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2587\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2588\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2589\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2590\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2591\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2592\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2593\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2594\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2595\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2596\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2597\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2598\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2599\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.6887, device='cuda:0')\n",
      "SAVED!\n",
      "Epoch:  2600\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2601\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2602\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.3939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2603\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2604\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2605\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2606\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2607\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2608\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2609\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2610\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2611\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2612\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2613\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2614\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2615\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2616\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2617\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2618\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2619\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7041, device='cuda:0')\n",
      "Epoch:  2620\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2621\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.3800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2622\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2623\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2624\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2625\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2626\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2627\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4313, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2628\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2629\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2630\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.1224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2631\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2632\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2633\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2634\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2635\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2636\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2637\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2638\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2639\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.6982, device='cuda:0')\n",
      "Epoch:  2640\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2641\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2642\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2643\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2644\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2645\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2646\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2647\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2648\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2649\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2650\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2651\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2652\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2653\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2654\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2655\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2656\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2657\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2658\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2659\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Current Validation Loss:  tensor(5.7076, device='cuda:0')\n",
      "Epoch:  2660\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2661\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2662\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2663\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2664\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.9156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2665\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2666\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2667\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2668\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2669\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2670\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.7046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2671\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(6.0821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2672\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.4726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2673\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2674\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2675\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2676\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2677\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.6597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2678\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.5167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch:  2679\n",
      "Average Epoch Loss (avg unsat clauses):  tensor(5.8132, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     param_group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lr_lower_bound\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (param_group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m lr_lower_bound) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[43mperformance_monitor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.999\u001b[39m\u001b[38;5;241m*\u001b[39mperformance_monitor[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m50\u001b[39m]):\n\u001b[1;32m     61\u001b[0m     param_group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m param_group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     63\u001b[0m curr_LR \u001b[38;5;241m=\u001b[39m  param_group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#####################TODOS:\n",
    "b_sizes = [16]\n",
    "l_rates = [0.001]\n",
    "depths = [10]\n",
    "#rand_seeds = list(range(70,80))\n",
    "rand_seeds = [3]\n",
    "widths = [128]\n",
    "\n",
    "num_iterations_per_epoch = 10\n",
    "\n",
    "wandb_logging = False  \n",
    "rnn_its = 1\n",
    "epochs = 5000\n",
    "retdict = {}\n",
    "edge_drop_p = 0.0\n",
    "edge_dropout_decay = 0.90\n",
    "validation_timeout = 75\n",
    "vis_batch = None\n",
    "vis_batches = []\n",
    "performance_monitor = []\n",
    "curr_date = date.today()\n",
    "curr_date = curr_date.strftime(\"%B %d, %Y\")\n",
    "curr_LR = None\n",
    "for batch_size, learning_rate, numlayers,  r_seed, hidden_1 in product(b_sizes, l_rates, depths, rand_seeds, widths):\n",
    "\n",
    "    torch.manual_seed(r_seed)\n",
    "    valdata = big_large_easy_validation\n",
    "    val_loader =  DataLoader(valdata, batch_size, shuffle=False)\n",
    "\n",
    "#####Set up data and loaders \n",
    "    if not infinite_data:\n",
    "        traindata= big_large_easy_train\n",
    "        train_loader = DataLoader(traindata, batch_size, shuffle=True)\n",
    "\n",
    "#####Set up model and relevant vars\n",
    "    #num_sat_instances =  sum([1*data.sat for data in traindata])\n",
    "    val_losses = []\n",
    "    cliq_dists = []\n",
    "    #hidden_1 = 128\n",
    "    hidden_2 = 2\n",
    "    net =  Erdos_MPNN(num_layers = numlayers, hidden1= hidden_1, hidden2 = hidden_2 ,num_iterations=rnn_its)\n",
    "    net.to(device).reset_parameters()\n",
    "    optimizer = Adam(net.parameters(), lr=learning_rate, weight_decay=0.00000)\n",
    "    net.train()\n",
    "    graphs_solved_LLL = 0\n",
    "    graphs_solved_LLL_previous = 0\n",
    "    #with torch.autograd.set_detect_anomaly(True):\n",
    "    for epoch in range(epochs):\n",
    "        count = 0\n",
    "        avg_epoch_loss = 0\n",
    "        totalretdict = {}\n",
    "        #learning rate schedule\n",
    "        if epoch % lr_decay_step_size == 0:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                        new_lr = lr_decay_factor * param_group['lr']\n",
    "                        if new_lr > lr_lower_bound:\n",
    "                            param_group['lr'] = new_lr\n",
    "                        else:\n",
    "                            param_group['lr'] = lr_lower_bound\n",
    "                        if (param_group['lr'] <= lr_lower_bound) and (performance_monitor[-1] <= 0.999*performance_monitor[-50]):\n",
    "                            param_group['lr'] = param_group['lr']*1\n",
    "\n",
    "                        curr_LR =  param_group['lr']\n",
    "                \n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                for data in val_loader:\n",
    "                    count += 1 \n",
    "                    optimizer.zero_grad(), \n",
    "                    data = data.to(device)\n",
    "                    retdict = net(data)\n",
    "                    val_loss += retdict[\"loss\"][0]/len(val_loader)\n",
    "                    optimizer.zero_grad()\n",
    "        \n",
    "            print(\"Current Validation Loss: \", val_loss)\n",
    "            val_losses += [val_loss]\n",
    "            #parent_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "            PATH = \"ErdoSAT_repo/\"+str(val_loss.item())+str(epoch)+\"ErdoSATmodel.pt\"\n",
    "            if ((val_loss<=torch.stack(val_losses))*1.).prod():\n",
    "                 print(\"SAVED!\")\n",
    "                 torch.save({'epoch': epoch,'model_state_dict': net.state_dict(),'optimizer_state_dict': optimizer.state_dict(),'loss': val_loss.item()}, PATH)                 \n",
    "\n",
    "\n",
    "\n",
    "        ####Infinite data\n",
    "        if infinite_data:\n",
    "            traindata = generate_RandomCNFDataset(num_iterations_per_epoch*batch_size,3,100,400,num_variables_high=101, num_clauses_high=401,verbose=False);\n",
    "            train_loader = DataLoader(traindata, batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "        print('Epoch: ', epoch)\n",
    "        net.train()\n",
    "        for data in train_loader:\n",
    "            count += 1 \n",
    "            optimizer.zero_grad(), \n",
    "            data = data.to(device)\n",
    "            retdict = net(data)\n",
    "            loss = retdict[\"loss\"][0]\n",
    "            avg_epoch_loss += loss/len(train_loader)\n",
    "            for key,val in retdict.items():\n",
    "                if \"sequence\" in val[1]:\n",
    "                    if key in totalretdict:\n",
    "                        totalretdict[key][0] += val[0].item()\n",
    "                    else:\n",
    "                        totalretdict[key] = [val[0].item(),val[1]]\n",
    "            if epoch > 1:\n",
    "                    loss.backward()\n",
    "                    #print(retdict[\"loss\"][0])\n",
    "                    #torch.nn.utils.clip_grad_norm_(net.parameters(),4.)\n",
    "                    optimizer.step()\n",
    "            else:\n",
    "                    optimizer.zero_grad()\n",
    "        print(\"Average Epoch Loss (avg unsat clauses): \", avg_epoch_loss)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lovasz_MPNN"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###LOAD CHECKPOINT (can skip that step)\n",
    "checkpoint = torch.load('ErdoSAT_repo/tensor(6.2546980ErdoSATmodel.pt')\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aspect/anaconda3/envs/extensions/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current batch:  0\n",
      "Current batch:  1\n",
      "Current batch:  2\n",
      "Current batch:  3\n",
      "Current batch:  4\n",
      "Current batch:  5\n",
      "Current batch:  6\n",
      "Current batch:  7\n",
      "Current batch:  8\n",
      "Current batch:  9\n",
      "Current batch:  10\n",
      "Current batch:  11\n",
      "Current batch:  12\n",
      "Current batch:  13\n",
      "Current batch:  14\n",
      "Current batch:  15\n",
      "Current batch:  16\n",
      "Current batch:  17\n",
      "Current batch:  18\n",
      "Current batch:  19\n",
      "Current batch:  20\n",
      "Current batch:  21\n",
      "Current batch:  22\n",
      "Current batch:  23\n",
      "Current batch:  24\n",
      "Current batch:  25\n",
      "Current batch:  26\n",
      "Current batch:  27\n",
      "Current batch:  28\n",
      "Current batch:  29\n",
      "Current batch:  30\n",
      "Current batch:  31\n",
      "Current batch:  32\n",
      "Current batch:  33\n",
      "Current batch:  34\n",
      "Current batch:  35\n",
      "Current batch:  36\n",
      "Current batch:  37\n",
      "Current batch:  38\n",
      "Current batch:  39\n",
      "Current batch:  40\n",
      "Current batch:  41\n",
      "Current batch:  42\n",
      "Current batch:  43\n",
      "Current batch:  44\n",
      "Current batch:  45\n",
      "Current batch:  46\n",
      "Current batch:  47\n",
      "Current batch:  48\n",
      "Current batch:  49\n",
      "Current batch:  50\n",
      "Current batch:  51\n",
      "Current batch:  52\n",
      "Current batch:  53\n",
      "Current batch:  54\n",
      "Current batch:  55\n",
      "Current batch:  56\n",
      "Current batch:  57\n",
      "Current batch:  58\n",
      "Current batch:  59\n",
      "Current batch:  60\n",
      "Current batch:  61\n",
      "Current batch:  62\n"
     ]
    }
   ],
   "source": [
    "dataset = test_dataset_torch\n",
    "test_loader = DataLoader(test_dataset_torch, batch_size, shuffle=False)\n",
    "expected_unsat_clauses_before =  []\n",
    "unsat_clauses_after = []\n",
    "\n",
    "batch_counter = 0\n",
    "\n",
    "for data in test_loader:\n",
    "    net.eval()\n",
    "    data = data.to(device)\n",
    "    retdict = net(data)\n",
    "    print(\"Current batch: \", batch_counter)\n",
    "\n",
    "    batch_probs = retdict['output'][0]\n",
    "    new_batch_probs = batch_probs.detach()\n",
    "\n",
    "    for graph_no,graph in enumerate(data.to_data_list()):\n",
    "        probs = batch_probs[data.batch==graph_no]\n",
    "        select_vars = (graph.x==0)\n",
    "        select_clauses = (graph.x==1)\n",
    "        d_row, d_col = graph.edge_index.detach()\n",
    "        edge_attr = graph.edge_attr.detach()\n",
    "        pos_assoc = edge_attr*((edge_attr>0)*1.)\n",
    "        neg_assoc = edge_attr*((edge_attr<0)*1.)\n",
    "        pos_neg_index = (graph.edge_attr==-1)*1.\n",
    "        new_probs = probs.detach()\n",
    "        new_var_probs = new_probs[select_vars]\n",
    "        \n",
    "\n",
    "\n",
    "        comp_msg = pos_neg_index *( new_probs[d_row]) + (1-pos_neg_index)*(1-new_probs[d_row])\n",
    "        pre_exp_comp = scatter(torch.log(comp_msg),d_col,dim=0, reduce=\"sum\")\n",
    "        transformed_probs_comp = torch.exp(pre_exp_comp)\n",
    "        clause_probs_comp = transformed_probs_comp.squeeze(-1)*((select_clauses)*1.) #shape: x\n",
    "        clause_probs_comp  = clause_probs_comp[select_clauses]\n",
    "        running_expected_clause_violation = clause_probs_comp.sum()\n",
    "        expected_unsat_clauses_before +=  [running_expected_clause_violation]\n",
    "\n",
    "\n",
    "        for counter in range(len(new_var_probs)):\n",
    "            if (new_var_probs[counter]<=1e-4):\n",
    "                new_var_probs[counter]=0.\n",
    "                continue\n",
    "            elif (new_var_probs[counter]>0.9999):\n",
    "                new_var_probs[counter]=1.\n",
    "                continue\n",
    "            p1 = new_var_probs[counter].detach()\n",
    "            one_minus_p1 = 1-p1\n",
    "            new_var_probs[counter] = 1.\n",
    "            #print(\"new probs value2\", new_var_probs[counter])\n",
    "\n",
    "            comp_msg = pos_neg_index *(new_var_probs[d_row]) + (1-pos_neg_index)*(1-new_var_probs[d_row])\n",
    "            pre_exp_comp = scatter(torch.log(comp_msg),d_col,dim=0, reduce=\"sum\")\n",
    "            transformed_probs_comp = torch.exp(pre_exp_comp)\n",
    "            clause_probs_comp = transformed_probs_comp.squeeze(-1)*((select_clauses)*1.) #shape: x\n",
    "            clause_probs_comp  = clause_probs_comp[select_clauses]\n",
    "            expected_clause_violation_1 = clause_probs_comp.sum()\n",
    "\n",
    "            \n",
    "            if expected_clause_violation_1<=running_expected_clause_violation:\n",
    "                #print(\"I'm here1\")\n",
    "                new_var_probs[counter] = 1.\n",
    "                running_expected_clause_violation = expected_clause_violation_1\n",
    "            else:\n",
    "                #print(\"ACTUALLY\")\n",
    "                new_var_probs[counter] = 0.\n",
    "                comp_msg = pos_neg_index *(new_var_probs[d_row]) + (1-pos_neg_index)*(1-new_var_probs[d_row])\n",
    "                pre_exp_comp = scatter(torch.log(comp_msg),d_col,dim=0, reduce=\"sum\")\n",
    "                transformed_probs_comp = torch.exp(pre_exp_comp)\n",
    "                clause_probs_comp = transformed_probs_comp.squeeze(-1)*((select_clauses)*1.) #shape: x\n",
    "                clause_probs_comp  = clause_probs_comp[select_clauses]\n",
    "                expected_clause_violation_0 = clause_probs_comp.sum()\n",
    "               # expected_clause_violation_0 = (running_expected_clause_violation - p1*expected_clause_violation_1)/one_minus_p1\n",
    "                running_expected_clause_violation = expected_clause_violation_0\n",
    "            #print(\"new probs value3\", new_var_probs[counter])\n",
    "\n",
    "\n",
    "        unsat_clauses_after +=[running_expected_clause_violation]\n",
    "            #var_probs = probs[select_vars].detach()\n",
    "        new_batch_probs[data.batch==graph_no] = new_probs\n",
    "\n",
    "    batch_counter +=1\n",
    "    #calculate for 1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##SANITY CHECK: print 1 if scores after decoding must be equal or better than before decoding (expected behavior)\n",
    "((torch.stack(expected_unsat_clauses_before)>=torch.stack(unsat_clauses_after))*1.).prod()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unsat clauses is 6.079092502593994+/-2.0700221061706543\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of unsat clauses is {torch.stack(unsat_clauses_after).mean()}+/-{torch.stack(unsat_clauses_after).std()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "0e05d59f657a364f03308f37a9206f937286d15320c19782c29632429d4e08a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
